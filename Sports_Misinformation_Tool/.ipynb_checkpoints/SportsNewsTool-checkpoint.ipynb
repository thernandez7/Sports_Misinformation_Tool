{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72517dfa-1720-49e6-b55a-f15cdf181498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/Combine_RSS_CSVs-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/SportsNewsTool-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/All_RSS_articles.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/Combine_RSS_CSVs.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/SportsNewsTool.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/Euro_tweets_initial_hueristic_sample-checkpoint.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/heuristic_analysis-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/real_european-checkpoint.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/Euro_tweets_initial_hueristic_exploration.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/Euro_tweets_initial_hueristic_sample.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/RSS_sports_feeds_11-17.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/fake_european.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/heuristic_analysis.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/real_european.csv', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main fa9692b] ran heuristic features on euro dataset and updated RSS collection\n",
      " 15 files changed, 169252 insertions(+), 148 deletions(-)\n",
      " create mode 100644 Sports_Misinformation_Tool/.ipynb_checkpoints/Euro_tweets_initial_hueristic_exploration-checkpoint.csv\n",
      " create mode 100644 Sports_Misinformation_Tool/.ipynb_checkpoints/Euro_tweets_initial_hueristic_sample-checkpoint.csv\n",
      " create mode 100644 Sports_Misinformation_Tool/.ipynb_checkpoints/heuristic_analysis-checkpoint.ipynb\n",
      " create mode 100644 Sports_Misinformation_Tool/.ipynb_checkpoints/real_european-checkpoint.csv\n",
      " create mode 100644 Sports_Misinformation_Tool/Euro_tweets_initial_hueristic_exploration.csv\n",
      " create mode 100644 Sports_Misinformation_Tool/Euro_tweets_initial_hueristic_sample.csv\n",
      " create mode 100644 Sports_Misinformation_Tool/RSS_sports_feeds_11-17.csv\n",
      " create mode 100644 Sports_Misinformation_Tool/fake_european.csv\n",
      " create mode 100644 Sports_Misinformation_Tool/heuristic_analysis.ipynb\n",
      " create mode 100644 Sports_Misinformation_Tool/real_european.csv\n",
      "Already up to date.\n",
      "branch 'main' set up to track 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:thernandez7/Sports_Misinformation_Tool.git\n",
      "   143b2a3..fa9692b  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"ran heuristic features on euro dataset and updated RSS collection\"\n",
    "!git pull\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bc5e79-db2d-4764-81e0-c13cc4ca8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446acb8-a93e-418e-a0ec-3ef05f7389b8",
   "metadata": {},
   "source": [
    "## Sports Misinformation Classification Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc105918-5fb3-432a-b47f-f3717be38100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e525a-1cf9-47be-8298-238a25ce2667",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Connect to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fde6c4b-1920-4bb2-846f-61455f869aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully!\n"
     ]
    }
   ],
   "source": [
    "username = 'root'  \n",
    "password = 'password'\n",
    "host = 'localhost' \n",
    "database = 'sports_news_db'\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host=host,\n",
    "    user=username,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "if connection.is_connected():\n",
    "    print(\"Connected to the database successfully!\")\n",
    "\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{username}:{password}@{host}/{database}\", echo=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70ed146f-9fe7-4370-a3d2-898811f3e183",
   "metadata": {},
   "source": [
    "#### Use this format to insert into the database\n",
    "\n",
    "INSERT INTO articles (team_or_player, source, publication_date, content, trust_score, classification, link)\n",
    "VALUES\n",
    "('New York Yankees, Los Angeles Lakers', 'ESPN', '2024-10-27', 'Yankees article content example.', 85.00, 'real', 'https://example.com/article1'),\n",
    "('Los Angeles Lakers', 'Twitter', '2024-10-27', 'Lakers article content example.', 60.00, 'fake', 'https://example.com/article2');\n",
    "\n",
    "\n",
    "#### Table fields \n",
    "Table Name: articles\n",
    "\n",
    "Fields: \n",
    "\n",
    "     id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "     \n",
    "     team_or_player VARCHAR(500), (This will be the article title that we can query- usually includes teams or names in it)\n",
    "     \n",
    "     source VARCHAR(200),\n",
    "     \n",
    "     publication_date DATE,\n",
    "     \n",
    "     content TEXT,\n",
    "     \n",
    "     trust_score DECIMAL(5, 2), \n",
    "     \n",
    "     classification ENUM('credible', 'uncredible', 'unknown') DEFAULT 'unknown',\n",
    "\n",
    "     link VARCHAR(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359168cc-f336-4972-b580-38575b45a13e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Simulate Tool Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9687e8d1-8c66-4df1-80cf-4bcf6f33805c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the team or player's name:  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No articles found for x.\n"
     ]
    }
   ],
   "source": [
    "team_or_player = input(\"Enter the team or player's name: \")\n",
    "\n",
    "query = f\"SELECT * FROM articles WHERE team_or_player LIKE '%{team_or_player}%'\" #search for entered name/team in the title \n",
    "df_result = pd.read_sql(query, con=engine, params={'team_or_player': team_or_player})\n",
    "\n",
    "#get results\n",
    "if not df_result.empty:\n",
    "    print(f\"Articles related to {team_or_player}:\")\n",
    "    display(df_result)\n",
    "else:\n",
    "    print(f\"No articles found for {team_or_player}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cee353-47af-48c3-a0eb-cf19ddcbc995",
   "metadata": {},
   "source": [
    "### Get Article Entries from RSS Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ea0136-a9b1-4fac-94f6-1949deec9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reddit API - collected 1876 posts\n",
    "# import csv\n",
    "# import praw\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "# reddit = praw.Reddit(\n",
    "#     client_id='w-kwRyPigyjYeG9DOiDc8g', \n",
    "#     client_secret='ZeDsvNH2YlpVH7F9wEWPkt5wkjLzqA',  \n",
    "#     user_agent='sports_misinfo_script'  \n",
    "# )\n",
    "\n",
    "# subreddit = reddit.subreddit('sports+fantasyfootball') #2 subreddits \n",
    "\n",
    "# recent_posts = []\n",
    "# for post in subreddit.new(limit= 5000):\n",
    "#     created_date = datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "#     recent_posts.append({\n",
    "#         'title': post.title,\n",
    "#         'score': post.score,\n",
    "#         'url': post.url,\n",
    "#         'id': post.id,\n",
    "#         'author': str(post.author),\n",
    "#         'text': post.selftext,\n",
    "#         'created_date': created_date,\n",
    "#         'num_comments': post.num_comments,\n",
    "#         'subreddit': post.subreddit.display_name,\n",
    "\n",
    "#     })\n",
    "\n",
    "# print(f\"Fetched {len(recent_posts)} posts\")\n",
    "\n",
    "# for i, post in enumerate(recent_posts[:5]):\n",
    "#     print(f\"{i+1}. Title: {post['title']} | Score: {post['score']} | URL: {post['url']}\")\n",
    "\n",
    "\n",
    "# #-------------------------------\n",
    "# #Save the data to a csv file\n",
    "# fieldnames = ['title', 'score', 'url', 'id', 'author', 'text', 'created_date', 'num_comments', 'subreddit']\n",
    "\n",
    "# with open('recent_sports_reddit_posts.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "#     writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "#     writer.writeheader()\n",
    "\n",
    "#     for post in recent_posts:\n",
    "#         writer.writerow(post)\n",
    "\n",
    "# print(\"Data successfully saved to 'recent_sports_reddit_posts.csv'\")\n",
    "# print(\"Data saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334d2970-7ee0-47e1-80d9-e01ae15fa4a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42446706/nfl-cowboys-texans-dak-prescott-jury-duty-sun-jerry-jones: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42446706/nfl-cowboys-texans-dak-prescott-jury-duty-sun-jerry-jones\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42447329/houston-texans-nico-collins-returns-mnf-dallas-cowboys: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42447329/houston-texans-nico-collins-returns-mnf-dallas-cowboys\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42472381/pittsburgh-pirates-ace-paul-skenes-named-nl-rookie-year: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42472381/pittsburgh-pirates-ace-paul-skenes-named-nl-rookie-year\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42463777/sources-giants-bench-qb-daniel-jones-turn-tommy-devito: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42463777/sources-giants-bench-qb-daniel-jones-turn-tommy-devito\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42470734/baltimore-ravens-try-competitors-justin-tucker: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42470734/baltimore-ravens-try-competitors-justin-tucker\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42470976/jags-coach-doug-pederson-says-blame-year-starts-him: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42470976/jags-coach-doug-pederson-says-blame-year-starts-him\n",
      "Failed to scrape content from https://www.espn.com/mens-college-basketball/story/_/id/42468114/kansas-remains-no-1-ap-top-25-hoops-poll-purdue-6: 403 Client Error: Forbidden for url: https://www.espn.com/mens-college-basketball/story/_/id/42468114/kansas-remains-no-1-ap-top-25-hoops-poll-purdue-6\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42471008/wr-tyquan-thornton-plans-sign-chiefs: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42471008/wr-tyquan-thornton-plans-sign-chiefs\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42466823/ichiro-suzuki-cc-sabathia-14-newcomers-hall-fame-ballot: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42466823/ichiro-suzuki-cc-sabathia-14-newcomers-hall-fame-ballot\n",
      "Failed to scrape content from https://www.espn.com/nba/story/_/id/42469818/lakers-honor-ex-coach-pat-riley-statue-arena: 403 Client Error: Forbidden for url: https://www.espn.com/nba/story/_/id/42469818/lakers-honor-ex-coach-pat-riley-statue-arena\n",
      "Failed to scrape content from https://www.espn.com/nba/story/_/id/42455306/the-offseason-plan-fueling-cleveland-cavaliers-top-nba: 403 Client Error: Forbidden for url: https://www.espn.com/nba/story/_/id/42455306/the-offseason-plan-fueling-cleveland-cavaliers-top-nba\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42372887/2024-mlb-awards-mvp-cy-young-rookie-manager-year-predictions-results-analysis: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42372887/2024-mlb-awards-mvp-cy-young-rookie-manager-year-predictions-results-analysis\n",
      "Failed to scrape content from https://www.espn.com/boxing/story/_/id/42419370/after-mike-tyson-jake-paul-surprised-see-boxing-spectacle-again: 403 Client Error: Forbidden for url: https://www.espn.com/boxing/story/_/id/42419370/after-mike-tyson-jake-paul-surprised-see-boxing-spectacle-again\n",
      "Failed to scrape content from https://www.espn.com/nhl/story/_/id/42269524/alex-ovechkin-goal-tracker-highlights-schedule-wayne-gretzky-all: 403 Client Error: Forbidden for url: https://www.espn.com/nhl/story/_/id/42269524/alex-ovechkin-goal-tracker-highlights-schedule-wayne-gretzky-all\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42393651/2024-college-football-power-rankings-week-12-top-25-teams: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42393651/2024-college-football-power-rankings-week-12-top-25-teams\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/page/gamedayfinal111624/college-football-week-12-highlights-top-plays-games-takeaways-2024: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/page/gamedayfinal111624/college-football-week-12-highlights-top-plays-games-takeaways-2024\n",
      "Failed to scrape content from https://www.espn.com/mens-college-basketball/story/_/id/42465726/ap-mens-college-basketball-2024-25-poll-reaction-next-top-25-team: 403 Client Error: Forbidden for url: https://www.espn.com/mens-college-basketball/story/_/id/42465726/ap-mens-college-basketball-2024-25-poll-reaction-next-top-25-team\n",
      "Failed to scrape content from https://www.espn.com/womens-college-basketball/story/_/id/42445823/ap-women-college-basketball-poll-reaction-next-top-25-team: 403 Client Error: Forbidden for url: https://www.espn.com/womens-college-basketball/story/_/id/42445823/ap-women-college-basketball-poll-reaction-next-top-25-team\n",
      "Failed to scrape content from https://www.espn.com/wnba/story/_/id/42370750/wnba-mock-draft-2025-paige-bueckers-draft-lottery-los-angeles-sparks-dallas-wings-washington-mystics-chicago-sky: 403 Client Error: Forbidden for url: https://www.espn.com/wnba/story/_/id/42370750/wnba-mock-draft-2025-paige-bueckers-draft-lottery-los-angeles-sparks-dallas-wings-washington-mystics-chicago-sky\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/40645589/mbappe-pulisic-most-expensive-u21-transfers-signings-projections: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/40645589/mbappe-pulisic-most-expensive-u21-transfers-signings-projections\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42465206/ruben-amorim-takes-man-united-training-visa-issues-fixed: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42465206/ruben-amorim-takes-man-united-training-visa-issues-fixed\n",
      "Failed to scrape content from https://www.espn.com/espn/story/_/id/42461366/soccer-stars-sam-kerr-kristie-mewis-announce-pregnancy: 403 Client Error: Forbidden for url: https://www.espn.com/espn/story/_/id/42461366/soccer-stars-sam-kerr-kristie-mewis-announce-pregnancy\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42462697/paul-pogba-keen-restart-career-europe-ban-sources: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42462697/paul-pogba-keen-restart-career-europe-ban-sources\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42453924/yohannes-named-uswnt-rodman-smith-left-out: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42453924/yohannes-named-uswnt-rodman-smith-left-out\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42462063/tottenham-rodrigo-bentancur-banned-7-games-son-heung-min-slur: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42462063/tottenham-rodrigo-bentancur-banned-7-games-son-heung-min-slur\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42463225/harry-kane-statue-unveiled-london-ireland-thrashing: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42463225/harry-kane-statue-unveiled-london-ireland-thrashing\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42464343/toby-alderweireld-says-panic-attacks-ended-belgium-career: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42464343/toby-alderweireld-says-panic-attacks-ended-belgium-career\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42461498/viktor-gyokeres-plays-man-united-links-concrete: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42461498/viktor-gyokeres-plays-man-united-links-concrete\n",
      "Failed to scrape content from https://www.espn.com/mma/story/_/id/42452267/ufc-309-next-jon-jones-charles-oliveira-michael-chandler-bo-nickal: 403 Client Error: Forbidden for url: https://www.espn.com/mma/story/_/id/42452267/ufc-309-next-jon-jones-charles-oliveira-michael-chandler-bo-nickal\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42454270/marta-orlando-pride-book-most-anticipated-nwsl-final-ever: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42454270/marta-orlando-pride-book-most-anticipated-nwsl-final-ever\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42471941/soccer-transfer-rumors-news-barcelona-view-nico-williams-priority: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42471941/soccer-transfer-rumors-news-barcelona-view-nico-williams-priority\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42388116/premier-league-manchester-city-chelsea-arsenal-tottenham-manchester-united-january-transfer: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42388116/premier-league-manchester-city-chelsea-arsenal-tottenham-manchester-united-january-transfer\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42453841/nfl-packers-christian-watson-jordan-love-jayden-reed: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42453841/nfl-packers-christian-watson-jordan-love-jayden-reed\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42452484/los-angeles-rams-puka-nacua-known-play-hard-sustainable-new-england-patriots: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42452484/los-angeles-rams-puka-nacua-known-play-hard-sustainable-new-england-patriots\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42470038/pop-tarts-bowl-2024-three-edible-mascots: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42470038/pop-tarts-bowl-2024-three-edible-mascots\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42450967/nfl-week-11-trolls: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42450967/nfl-week-11-trolls\n",
      "Failed to scrape content from https://www.espn.com/fantasy/basketball/story/_/id/42466986/fantasy-basketball-waiver-wire-pickups-nba-week-5-shaedon-sharpe-alexandre-sarr: 403 Client Error: Forbidden for url: https://www.espn.com/fantasy/basketball/story/_/id/42466986/fantasy-basketball-waiver-wire-pickups-nba-week-5-shaedon-sharpe-alexandre-sarr\n",
      "Failed to scrape content from https://www.espn.com/fantasy/football/story/_/id/42452011/fantasy-football-2024-week-11-rookies-brock-bowers-bo-nix-drake-maye-rome-odunze: 403 Client Error: Forbidden for url: https://www.espn.com/fantasy/football/story/_/id/42452011/fantasy-football-2024-week-11-rookies-brock-bowers-bo-nix-drake-maye-rome-odunze\n",
      "Failed to scrape content from https://www.espn.com/nhl/story/_/id/42390646/nhl-power-rankings-2024-2025-best-teams-standings-fantasy-hockey: 403 Client Error: Forbidden for url: https://www.espn.com/nhl/story/_/id/42390646/nhl-power-rankings-2024-2025-best-teams-standings-fantasy-hockey\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42461229/barcelona-ease-clasico-win-real-madrid-chelsea-beat-city-arsenal-spurs: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42461229/barcelona-ease-clasico-win-real-madrid-chelsea-beat-city-arsenal-spurs\n",
      "Failed to scrape content from https://www.espn.com/boxing/story/_/id/42422294/katie-taylor-amanda-serrano-jake-paul-mike-tyson-boxing: 403 Client Error: Forbidden for url: https://www.espn.com/boxing/story/_/id/42422294/katie-taylor-amanda-serrano-jake-paul-mike-tyson-boxing\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-dominik-mysterio-breaks-silence-major-loss-wwe-raw: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-dominik-mysterio-breaks-silence-major-loss-wwe-raw\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/when-wwe-legend-went-script-kissed-becky-lynch-live-tv: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/when-wwe-legend-went-script-kissed-becky-lynch-live-tv\n",
      "Failed to scrape content from https://www.sportskeeda.com/college-football/news-kyron-drones-injury-update-virginia-tech-coach-shares-current-status-hokies-qb: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/college-football/news-kyron-drones-injury-update-virginia-tech-coach-shares-current-status-hokies-qb\n",
      "Failed to scrape content from https://www.sportskeeda.com/aew/news-aew-creates-buzz-mysterious-trademark-filing: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/aew/news-aew-creates-buzz-mysterious-trademark-filing\n",
      "Failed to scrape content from https://www.sportskeeda.com/baseball/news-are-paying-kike-hernandez-minimum-wage-should-run-president-fans-amused-dodgers-star-serves-fans-food-celebrate-world-series-win: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/baseball/news-are-paying-kike-hernandez-minimum-wage-should-run-president-fans-amused-dodgers-star-serves-fans-food-celebrate-world-series-win\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/news-joe-burrow-explains-upset-despite-251-yard-5-td-performance-routing-raiders: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/news-joe-burrow-explains-upset-despite-251-yard-5-td-performance-routing-raiders\n",
      "Failed to scrape content from https://www.sportskeeda.com/us/olympics/news-simone-biles-drops-two-word-reaction-gold-over-america-tour-gymnast-yul-moldauer-s-heartfelt-note-upon-conclusion-shows: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/us/olympics/news-simone-biles-drops-two-word-reaction-gold-over-america-tour-gymnast-yul-moldauer-s-heartfelt-note-upon-conclusion-shows\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/news-did-daniel-jones-tell-teammates-vote-debunking-viral-myth-giants-qb: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/news-did-daniel-jones-tell-teammates-vote-debunking-viral-myth-giants-qb\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-sami-zayn-shares-two-word-message-ahead-potential-og-bloodline-reunion-wwe-smackdown: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-sami-zayn-shares-two-word-message-ahead-potential-og-bloodline-reunion-wwe-smackdown\n",
      "Failed to scrape content from https://www.sportskeeda.com/baseball/news-shohei-ohtani-injury-update-dodgers-star-undergoes-surgery-torn-left-labrum-expected-ready-spring-training: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/baseball/news-shohei-ohtani-injury-update-dodgers-star-undergoes-surgery-torn-left-labrum-expected-ready-spring-training\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/tee-higgins-injury-update-should-fantasy-managers-concerned-bengals-wr-week-10-fantasy-football: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/tee-higgins-injury-update-should-fantasy-managers-concerned-bengals-wr-week-10-fantasy-football\n",
      "Failed to scrape content from https://www.sportskeeda.com/aew/news-kenny-omega-blatantly-takes-shot-cm-punk-aew-brawl-scathing-rant: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/aew/news-kenny-omega-blatantly-takes-shot-cm-punk-aew-brawl-scathing-rant\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/news-tom-brady-makes-priorities-clear-stunned-ex-wife-gisele-bundchen-s-pregnancy-page-six-report: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/news-tom-brady-makes-priorities-clear-stunned-ex-wife-gisele-bundchen-s-pregnancy-page-six-report\n",
      "Failed to scrape content from https://www.sportskeeda.com/baseball/7-dodgers-now-free-agents-ft-jack-flaherty-teoscar-hernandez: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/baseball/7-dodgers-now-free-agents-ft-jack-flaherty-teoscar-hernandez\n",
      "Failed to scrape content from https://www.sportskeeda.com/baseball/news-i-thought-i-blown-oblique-out-freddie-freeman-rib-injury-scare-threatened-journey-dodgers-world-series-win: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/baseball/news-i-thought-i-blown-oblique-out-freddie-freeman-rib-injury-scare-threatened-journey-dodgers-world-series-win\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-seth-rollins-surprisingly-names-aew-star-one-favorite-opponents-wwe: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-seth-rollins-surprisingly-names-aew-star-one-favorite-opponents-wwe\n",
      "Failed to scrape content from https://www.sportskeeda.com/kabaddi/tamil-thalaivas-vs-telugu-titans-prediction-who-will-win-today-s-pkl-match-no-38: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/kabaddi/tamil-thalaivas-vs-telugu-titans-prediction-who-will-win-today-s-pkl-match-no-38\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-sami-zayn-sends-message-og-bloodline-confronting-the-usos-reacts-meeting-roman-reigns: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-sami-zayn-sends-message-og-bloodline-confronting-the-usos-reacts-meeting-roman-reigns\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/lamar-jackson-injury-update-should-fantasy-managers-concerned-ravens-qb-week-10-fantasy-football: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/lamar-jackson-injury-update-should-fantasy-managers-concerned-ravens-qb-week-10-fantasy-football\n",
      "Failed to scrape content from https://www.sportskeeda.com/basketball/news-lebron-james-fan-nba-analyst-says-4x-nba-champ-big-part-lakers-problem-amid-horrid-road-stretch: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/basketball/news-lebron-james-fan-nba-analyst-says-4x-nba-champ-big-part-lakers-problem-amid-horrid-road-stretch\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#add urls to this list to parse\n",
    "url_list = [\n",
    "        #MBFC High Credibility-9 (add 1 to cred.)\n",
    "        \"https://www.espn.com/espn/rss/news\", #ESPN top headlines\n",
    "        \"https://deadspin.com/rss/\", #Deadspin \n",
    "        \"https://feeds.abcnews.com/abcnews/sportsheadlines\" #ABC news- espn sports\n",
    "        \"https://rss.nytimes.com/services/xml/rss/nyt/Sports.xml\", #NYT\n",
    "        \"https://www.nytimes.com/athletic/rss/news/\"#The Athletic- acquired by NYT\n",
    "        \"https://www.mlb.com/feeds/news/rss.xml\", #MLB news \n",
    "        \"https://www.reutersagency.com/feed/?best-topics=sports&post_type=best\", # Reuters\n",
    "        \"https://sports.yahoo.com/rss/\", #Yahoo News\n",
    "        \"https://www.cbssports.com/rss/headlines/\" #CBS sports general headlines \n",
    "\n",
    "        #MBFC questionable sources or medium credibility- 5 (add -.5)\n",
    "        \"https://notthebee.com/feed\", #not the bee\n",
    "        \"https://uproxx.com/sports/feed/\", #uproxx   \n",
    "        \"https://www.vibe.com/c/news/sports/feed/\", #The vibe - medium cred \n",
    "        \"https://moxie.foxnews.com/google-publisher/sports.xml\", #fox news \n",
    "        \"https://nypost.com/sports/feed/\" #NY post - medium cred\n",
    "\n",
    "        #NO MBFC RATING -11 (add 0)\n",
    "        \"https://www.sportscollectorsdaily.com/feed/\", #Sports Collectors Daily \n",
    "        \"https://news.sportslogos.net/feed/\", #SportsLogos.Net\n",
    "        \"https://www.sportingnews.com/us/rss\", #sportingnews.com\n",
    "        \"https://www.sportskeeda.com/feed\",#sportskeeda.com\n",
    "        \"https://sportsweez.com/feed/\", #sportsweez\n",
    "        \"https://sportsbrackets.net/feed/\", #sportsbracket\n",
    "        \"https://21sports.com/feed/\", # 21 sports\n",
    "        \"https://www.essentiallysports.com/feed/\", #essentiallysports\n",
    "        \"https://boxingnewsonline.net/feed/\", #boxing news\n",
    "        \"https://www.thecoldwire.com/feed/\", #the cold wire\n",
    "        \"https://sportsdark.com/feed/\", #sports dark\n",
    "]\n",
    "    \n",
    "entries = [] #list of dictionaries\n",
    "\n",
    "#--------------DEFINE FUNCTION TO SCRAPE-------------------\n",
    "def scrape_article_content(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        #extract content from common tags\n",
    "        article_body = (\n",
    "            soup.find(\"article\") or\n",
    "            soup.find(\"div\", {\"class\": \"post-content\"}) or\n",
    "            soup.find(\"div\", class_=\"article-body\") or\n",
    "            soup.find(\"div\", class_=\"article-content\") or\n",
    "            soup.find(\"section\", class_=\"article-section\") or\n",
    "            soup.find(\"div\", class_=\"main-content\") or\n",
    "            soup.find(\"div\", class_=\"content-body\")\n",
    "        )\n",
    "        \n",
    "        if article_body:\n",
    "            paragraphs = article_body.find_all(\"p\")\n",
    "        else:\n",
    "            paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "        #join all paragraphs into a single string\n",
    "        article_content = \" \".join(p.get_text() for p in paragraphs)\n",
    "        return article_content.strip() if article_content else \"No content found\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape content from {url}: {e}\")\n",
    "        return \"Failed to fetch content\"\n",
    "\n",
    "\n",
    "#run the function to collect feeds and scrape\n",
    "for url in url_list:\n",
    "    feed = feedparser.parse(url)\n",
    "    #feed_title= feed.feed.title\n",
    "    feed_title = getattr(feed.feed, \"title\", None)\n",
    "\n",
    "    \n",
    "    for entry in feed.entries:\n",
    "        entry_title = getattr(entry, \"title\", None)\n",
    "        entry_link = getattr(entry, \"link\", None)\n",
    "        entry_published_date = getattr(entry, \"published\", None)\n",
    "        entry_summary = getattr(entry, \"summary\", None)\n",
    "        entry_content = scrape_article_content(entry_link) #scrape\n",
    "        \n",
    "        entries.append({\n",
    "            \"feed_title\": feed_title,\n",
    "            \"entry_title\": entry_title,\n",
    "            \"entry_link\": entry_link,\n",
    "            \"entry_published_date\": entry_published_date,\n",
    "            \"entry_summary\": entry_summary,\n",
    "            \"entry_content\": entry_content,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(entries)\n",
    "#print(df)\n",
    "\n",
    "df.to_csv('RSS_sports_feeds_11-18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b17ce3-4167-4ee2-b75b-0e30f8d21697",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attempt to Scrape Links without RSS Feeds- not very effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9a3d96-4201-4150-8ecb-b14e133f886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# uncredible_urls = [\n",
    "#     \"https://www.tellerreport.com/sports\",\n",
    "#     \"https://www.newsbreak.com/mountain-view-ca-sports\",\n",
    "#     \"https://newsrnd.com/sports\",\n",
    "#     \"https://baltimorecitywire.com/stories/tag/53-sports\"\n",
    "# ]\n",
    "\n",
    "# # Function to scrape article details\n",
    "# def scrape_article(url):\n",
    "#     try:\n",
    "#         response = requests.get(url, timeout=10)\n",
    "#         response.raise_for_status()\n",
    "#         soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#         # Extract the article title\n",
    "#         title = soup.find(\"h1\").get_text() if soup.find(\"h1\") else soup.title.get_text()\n",
    "\n",
    "#         # Extract the publication date (common in <time> or meta tags)\n",
    "#         date = soup.find(\"time\")\n",
    "#         if date:\n",
    "#             publication_date = date.get(\"datetime\") or date.get_text()\n",
    "#         else:\n",
    "#             date_meta = soup.find(\"meta\", {\"name\": \"article:published_time\"})\n",
    "#             publication_date = date_meta[\"content\"] if date_meta else \"No date found\"\n",
    "\n",
    "#         # Extract the article content\n",
    "#         content_container = (\n",
    "#             soup.find(\"article\") or\n",
    "#             soup.find(\"div\", class_=[\"post-content\", \"article-body\", \"article-content\", \"content-body\"])\n",
    "#         )\n",
    "#         if content_container:\n",
    "#             paragraphs = content_container.find_all(\"p\")\n",
    "#         else:\n",
    "#             paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "#         content = \"\\n\".join(p.get_text() for p in paragraphs)\n",
    "\n",
    "#         return {\n",
    "#             \"Title\": title.strip(),\n",
    "#             \"Publication Date\": publication_date.strip(),\n",
    "#             \"Content\": content.strip()[:500] + \"...\",\n",
    "#             \"Link\": url\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to scrape {url}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# articles = []\n",
    "# for url in uncredible_urls:\n",
    "#     print(f\"Scraping: {url}\")\n",
    "#     article_details = scrape_article(url)\n",
    "#     if article_details:\n",
    "#         articles.append(article_details)\n",
    "\n",
    "# for article in articles:\n",
    "#     print(\"\\n--- Article ---\")\n",
    "#     print(f\"Title: {article['Title']}\")\n",
    "#     print(f\"Date: {article['Publication Date']}\")\n",
    "#     print(f\"Content Preview: {article['Content']}\")\n",
    "#     print(f\"Link: {article['Link']}\\n\")\n",
    "\n",
    "# df = pd.DataFrame(articles)\n",
    "# output_file = \"scraped_uncredible_articles.csv\"\n",
    "# df.to_csv(output_file, index=False)\n",
    "# print(f\"\\nResults saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f53448-164e-46d8-a16d-02c3dbaa7d0c",
   "metadata": {},
   "source": [
    "### Format DF to match DB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b6b1163a-ce9f-47f0-9c15-d7e5cceaf6e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tizia\\Anaconda4\\Lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "df['publication_date'] = df['entry_published_date'].apply(lambda x: parser.parse(x).date()) #parse different date formats to date object format\n",
    "dbdf = pd.read_csv('RSS_sports_feeds.csv')\n",
    "dbdf['team_or_player'] = df['entry_title']\n",
    "dbdf['source'] = df['feed_title']\n",
    "dbdf['publication_date'] = df['publication_date'] \n",
    "dbdf['content'] = df['entry_summary']\n",
    "dbdf['trust_score'] = 0.00  #default\n",
    "dbdf['classification'] = 'unknown' #default\n",
    "dbdf['link'] = df['entry_link']\n",
    "\n",
    "#make a new df in the format of the DB table for easy inserting\n",
    "sports_DB_df = dbdf[['team_or_player', 'source', 'publication_date', 'content', 'trust_score', 'classification', 'link']]\n",
    "#save to a new CSV \n",
    "sports_DB_df.to_csv('formatted_sports_posts_for_DB.csv', index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b923503-bb70-46cc-ad0c-a13fb1dbdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_euro_df = pd.read_csv('real_european.csv')\n",
    "fake_euro_df = pd.read_csv('fake_european.csv')\n",
    "\n",
    "real_euro_df[\"label\"] = \"True\"\n",
    "fake_euro_df[\"label\"] = \"False\"\n",
    "\n",
    "real_tweets= real_euro_df[\"tweet\"].dropna()\n",
    "fake_tweets= fake_euro_df[\"tweet\"].dropna()\n",
    "\n",
    "# Compute features for true and false tweets\n",
    "euro_true_features_df = compute_features(real_tweets)\n",
    "euro_false_features_df = compute_features(fake_tweets)\n",
    "\n",
    "euro_true_features_df[\"label\"] = \"True\"\n",
    "euro_false_features_df[\"label\"] = \"False\"\n",
    "\n",
    "euro_combined_df = pd.concat([euro_true_features_df, euro_false_features_df], ignore_index=True)\n",
    "euro_combined_df.to_csv(\"Euro_tweets_initial_hueristic_exploration.csv\")\n",
    "print(\"Data saved to 'Euro_tweets_initial_hueristic_exploration.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282d88e-3a8a-4283-af31-f011ec789135",
   "metadata": {},
   "source": [
    "### Define labeling heuristic and trust score to update sports_DB_df with ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a5014-fff8-4491-a937-cadbd2b697ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
