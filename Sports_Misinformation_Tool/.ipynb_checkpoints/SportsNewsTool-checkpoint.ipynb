{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72517dfa-1720-49e6-b55a-f15cdf181498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/Combine_RSS_CSVs-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/SportsNewsTool-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/All_RSS_articles.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/Combine_RSS_CSVs.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/SportsNewsTool.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/heuristic_analysis.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 6d17dfe] updated RSS collection\n",
      " 6 files changed, 997 insertions(+), 165 deletions(-)\n",
      "Already up to date.\n",
      "branch 'main' set up to track 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:thernandez7/Sports_Misinformation_Tool.git\n",
      "   5bbaa57..6d17dfe  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"updated RSS collection\"\n",
    "!git pull\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bc5e79-db2d-4764-81e0-c13cc4ca8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446acb8-a93e-418e-a0ec-3ef05f7389b8",
   "metadata": {},
   "source": [
    "## Sports Misinformation Classification Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc105918-5fb3-432a-b47f-f3717be38100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e525a-1cf9-47be-8298-238a25ce2667",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Connect to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fde6c4b-1920-4bb2-846f-61455f869aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully!\n"
     ]
    }
   ],
   "source": [
    "username = 'root'  \n",
    "password = 'password'\n",
    "host = 'localhost' \n",
    "database = 'sports_news_db'\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host=host,\n",
    "    user=username,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "if connection.is_connected():\n",
    "    print(\"Connected to the database successfully!\")\n",
    "\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{username}:{password}@{host}/{database}\", echo=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70ed146f-9fe7-4370-a3d2-898811f3e183",
   "metadata": {},
   "source": [
    "#### Use this format to insert into the database\n",
    "\n",
    "INSERT INTO articles (team_or_player, source, publication_date, content, trust_score, classification, link)\n",
    "VALUES\n",
    "('New York Yankees, Los Angeles Lakers', 'ESPN', '2024-10-27', 'Yankees article content example.', 85.00, 'real', 'https://example.com/article1'),\n",
    "('Los Angeles Lakers', 'Twitter', '2024-10-27', 'Lakers article content example.', 60.00, 'fake', 'https://example.com/article2');\n",
    "\n",
    "\n",
    "#### Table fields \n",
    "Table Name: articles\n",
    "\n",
    "Fields: \n",
    "\n",
    "     id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "     \n",
    "     team_or_player VARCHAR(500), (This will be the article title that we can query- usually includes teams or names in it)\n",
    "     \n",
    "     source VARCHAR(200),\n",
    "     \n",
    "     publication_date DATE,\n",
    "     \n",
    "     content TEXT,\n",
    "     \n",
    "     trust_score DECIMAL(5, 2), \n",
    "     \n",
    "     classification ENUM('credible', 'uncredible', 'unknown') DEFAULT 'unknown',\n",
    "\n",
    "     link VARCHAR(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359168cc-f336-4972-b580-38575b45a13e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Simulate Tool Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9687e8d1-8c66-4df1-80cf-4bcf6f33805c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the team or player's name:  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No articles found for x.\n"
     ]
    }
   ],
   "source": [
    "team_or_player = input(\"Enter the team or player's name: \")\n",
    "\n",
    "query = f\"SELECT * FROM articles WHERE team_or_player LIKE '%{team_or_player}%'\" #search for entered name/team in the title \n",
    "df_result = pd.read_sql(query, con=engine, params={'team_or_player': team_or_player})\n",
    "\n",
    "#get results\n",
    "if not df_result.empty:\n",
    "    print(f\"Articles related to {team_or_player}:\")\n",
    "    display(df_result)\n",
    "else:\n",
    "    print(f\"No articles found for {team_or_player}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cee353-47af-48c3-a0eb-cf19ddcbc995",
   "metadata": {},
   "source": [
    "### Get Article Entries from RSS Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ea0136-a9b1-4fac-94f6-1949deec9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reddit API - collected 1876 posts\n",
    "# import csv\n",
    "# import praw\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "# reddit = praw.Reddit(\n",
    "#     client_id='w-kwRyPigyjYeG9DOiDc8g', \n",
    "#     client_secret='ZeDsvNH2YlpVH7F9wEWPkt5wkjLzqA',  \n",
    "#     user_agent='sports_misinfo_script'  \n",
    "# )\n",
    "\n",
    "# subreddit = reddit.subreddit('sports+fantasyfootball') #2 subreddits \n",
    "\n",
    "# recent_posts = []\n",
    "# for post in subreddit.new(limit= 5000):\n",
    "#     created_date = datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "#     recent_posts.append({\n",
    "#         'title': post.title,\n",
    "#         'score': post.score,\n",
    "#         'url': post.url,\n",
    "#         'id': post.id,\n",
    "#         'author': str(post.author),\n",
    "#         'text': post.selftext,\n",
    "#         'created_date': created_date,\n",
    "#         'num_comments': post.num_comments,\n",
    "#         'subreddit': post.subreddit.display_name,\n",
    "\n",
    "#     })\n",
    "\n",
    "# print(f\"Fetched {len(recent_posts)} posts\")\n",
    "\n",
    "# for i, post in enumerate(recent_posts[:5]):\n",
    "#     print(f\"{i+1}. Title: {post['title']} | Score: {post['score']} | URL: {post['url']}\")\n",
    "\n",
    "\n",
    "# #-------------------------------\n",
    "# #Save the data to a csv file\n",
    "# fieldnames = ['title', 'score', 'url', 'id', 'author', 'text', 'created_date', 'num_comments', 'subreddit']\n",
    "\n",
    "# with open('recent_sports_reddit_posts.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "#     writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "#     writer.writeheader()\n",
    "\n",
    "#     for post in recent_posts:\n",
    "#         writer.writerow(post)\n",
    "\n",
    "# print(\"Data successfully saved to 'recent_sports_reddit_posts.csv'\")\n",
    "# print(\"Data saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334d2970-7ee0-47e1-80d9-e01ae15fa4a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42493104/boise-state-moves-ahead-byu-cfp-bye-territory: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42493104/boise-state-moves-ahead-byu-cfp-bye-territory\n",
      "Failed to scrape content from https://www.espn.com/tennis/story/_/id/42492215/rafael-nadal-career-ends-spain-eliminated-davis-cup: 403 Client Error: Forbidden for url: https://www.espn.com/tennis/story/_/id/42492215/rafael-nadal-career-ends-spain-eliminated-davis-cup\n",
      "Failed to scrape content from https://www.espn.com/nhl/story/_/id/42490989/boston-bruins-fire-coach-jim-montgomery-20-games: 403 Client Error: Forbidden for url: https://www.espn.com/nhl/story/_/id/42490989/boston-bruins-fire-coach-jim-montgomery-20-games\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42492742/cleveland-guardians-stephen-vogt-named-al-manager-year: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42492742/cleveland-guardians-stephen-vogt-named-al-manager-year\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42487178/sources-jets-fire-gm-joe-douglas-amid-woeful-season: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42487178/sources-jets-fire-gm-joe-douglas-amid-woeful-season\n",
      "Failed to scrape content from https://www.espn.com/nba/story/_/id/42486989/sources-tyrese-maxey-challenged-joel-embiid-76ers-meeting: 403 Client Error: Forbidden for url: https://www.espn.com/nba/story/_/id/42486989/sources-tyrese-maxey-challenged-joel-embiid-76ers-meeting\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42490594/colorado-deion-sanders-ignores-talk-aint-going-nowhere: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42490594/colorado-deion-sanders-ignores-talk-aint-going-nowhere\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42491676/big-ten-confirms-oregon-clinched-spot-title-game: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42491676/big-ten-confirms-oregon-clinched-spot-title-game\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42491439/mets-acquire-jose-siri-rays-reliever-eric-orze: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42491439/mets-acquire-jose-siri-rays-reliever-eric-orze\n",
      "Failed to scrape content from https://www.espn.com/nba/story/_/id/40544747/2024-nba-season-tournament-format-schedule-groups: 403 Client Error: Forbidden for url: https://www.espn.com/nba/story/_/id/40544747/2024-nba-season-tournament-format-schedule-groups\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42468446/nfl-power-rankings-week-12-poll-2024-evaluating-preseason-hot-seat: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42468446/nfl-power-rankings-week-12-poll-2024-evaluating-preseason-hot-seat\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42472542/college-football-2024-defense-stop-rate-week-13: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42472542/college-football-2024-defense-stop-rate-week-13\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42468936/can-florida-state-football-recover-historic-collapse: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42468936/can-florida-state-football-recover-historic-collapse\n",
      "Failed to scrape content from https://www.espn.com/espn/feature/story/_/id/30423107/ncaa-women-bracketology-2025-women-college-basketball-projections: 403 Client Error: Forbidden for url: https://www.espn.com/espn/feature/story/_/id/30423107/ncaa-women-bracketology-2025-women-college-basketball-projections\n",
      "Failed to scrape content from https://www.espn.com/espn/feature/story/_/page/bracketology/ncaa-bracketology-2025-march-madness-men-field-predictions: 403 Client Error: Forbidden for url: https://www.espn.com/espn/feature/story/_/page/bracketology/ncaa-bracketology-2025-march-madness-men-field-predictions\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42372887/2024-mlb-awards-mvp-cy-young-rookie-manager-year-predictions-results-analysis: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42372887/2024-mlb-awards-mvp-cy-young-rookie-manager-year-predictions-results-analysis\n",
      "Failed to scrape content from https://www.espn.com/tennis/story/_/id/42395852/rafael-nadal-retires-davis-cup-king-clay-greatest-tennis-players: 403 Client Error: Forbidden for url: https://www.espn.com/tennis/story/_/id/42395852/rafael-nadal-retires-davis-cup-king-clay-greatest-tennis-players\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42466271/manchester-city-future-pep-guardiola-hugo-viana-txiki-squad-transfers-analysis-premier-league: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42466271/manchester-city-future-pep-guardiola-hugo-viana-txiki-squad-transfers-analysis-premier-league\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42490046/nfl-bengals-jamarr-chase-zac-taylor: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42490046/nfl-bengals-jamarr-chase-zac-taylor\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42466407/nfl-offensive-coordinator-kellen-moore-kliff-kingsbury: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42466407/nfl-offensive-coordinator-kellen-moore-kliff-kingsbury\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42473136/nfl-bears-qb-caleb-williams-offensive-coordinator: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42473136/nfl-bears-qb-caleb-williams-offensive-coordinator\n",
      "Failed to scrape content from https://www.espn.com/fantasy/football/story/_/page/FFWeeklyPlayerRank24main-41028715/nfl-fantasy-football-rankings-2024-qb-rb-wr-te-dst: 403 Client Error: Forbidden for url: https://www.espn.com/fantasy/football/story/_/page/FFWeeklyPlayerRank24main-41028715/nfl-fantasy-football-rankings-2024-qb-rb-wr-te-dst\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42488235/kyler-murray-arizona-cardinals-new-york-city-joes-pizza: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42488235/kyler-murray-arizona-cardinals-new-york-city-joes-pizza\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42491149/usc-trojans-kobe-bryant-football-cleats-ucla-bruins: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42491149/usc-trojans-kobe-bryant-football-cleats-ucla-bruins\n",
      "Failed to scrape content from https://www.espn.com/mma/story/_/id/24067525/mma-pound-pound-rankings: 403 Client Error: Forbidden for url: https://www.espn.com/mma/story/_/id/24067525/mma-pound-pound-rankings\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/41248199/rooney-bellingham-mbappe-gvardiol-vinicius-most-expensive-u21-transfers-signings-projections: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/41248199/rooney-bellingham-mbappe-gvardiol-vinicius-most-expensive-u21-transfers-signings-projections\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42490094/pep-guardiola-man-city-new-contract: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42490094/pep-guardiola-man-city-new-contract\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42482733/ruben-amorim-denied-january-man-united-transfer-spree-source: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42482733/ruben-amorim-denied-january-man-united-transfer-spree-source\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42488934/fc-cincinnati-mls-transfer-record-cercle-brugge-kevin-denkey: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42488934/fc-cincinnati-mls-transfer-record-cercle-brugge-kevin-denkey\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42481878/barcelona-official-confirms-psg-bid-250m-lamine-yamal: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42481878/barcelona-official-confirms-psg-bid-250m-lamine-yamal\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42484038/sam-kerr-kristie-mewis-suffer-abuse-baby-announcement: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42484038/sam-kerr-kristie-mewis-suffer-abuse-baby-announcement\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42487921/genoa-fire-alberto-gilardino-coach-patrick-vieira-replacement: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42487921/genoa-fire-alberto-gilardino-coach-patrick-vieira-replacement\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42483295/washington-spirit-owner-michele-kang-pledges-30m-us-soccer: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42483295/washington-spirit-owner-michele-kang-pledges-30m-us-soccer\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42477019/pochettino-praises-usmnt-fantastic-performance-vs-jamaica-nations-league: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42477019/pochettino-praises-usmnt-fantastic-performance-vs-jamaica-nations-league\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42477423/usmnts-big-win-jamaica-gives-pochettino-era-lift-off: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42477423/usmnts-big-win-jamaica-gives-pochettino-era-lift-off\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42492191/soccer-transfer-rumors-news-arsenal-eyeing-possible-arda-guler-move: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42492191/soccer-transfer-rumors-news-arsenal-eyeing-possible-arda-guler-move\n",
      "Failed to scrape content from https://www.espn.com/espn/betting/story/_/id/42470775/nhl-odds-betting-goaltending-factor: 403 Client Error: Forbidden for url: https://www.espn.com/espn/betting/story/_/id/42470775/nhl-odds-betting-goaltending-factor\n",
      "Failed to scrape content from https://www.espn.com/boxing/story/_/id/42419370/after-mike-tyson-jake-paul-surprised-see-boxing-spectacle-again: 403 Client Error: Forbidden for url: https://www.espn.com/boxing/story/_/id/42419370/after-mike-tyson-jake-paul-surprised-see-boxing-spectacle-again\n",
      "Failed to scrape content from https://www.espn.com/mens-college-basketball/story/_/id/42469926/scnext-top-25-2024-25-preseason-high-school-boys-basketball-rankings: 403 Client Error: Forbidden for url: https://www.espn.com/mens-college-basketball/story/_/id/42469926/scnext-top-25-2024-25-preseason-high-school-boys-basketball-rankings\n",
      "Failed to scrape content from https://www.espn.com/womens-college-basketball/story/_/id/42485368/scnext-top-25-2024-25-high-school-girls-basketball-rankings: 403 Client Error: Forbidden for url: https://www.espn.com/womens-college-basketball/story/_/id/42485368/scnext-top-25-2024-25-high-school-girls-basketball-rankings\n",
      "Failed to scrape content from https://www.espn.com/fantasy/basketball/story/_/id/42486458/fantasy-basketball-nba-best-player-no-1-wemby-victor-wembanyama-nikola-jokiÄ‡: 403 Client Error: Forbidden for url: https://www.espn.com/fantasy/basketball/story/_/id/42486458/fantasy-basketball-nba-best-player-no-1-wemby-victor-wembanyama-nikola-joki%C4%87\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-dominik-mysterio-breaks-silence-major-loss-wwe-raw: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-dominik-mysterio-breaks-silence-major-loss-wwe-raw\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/when-wwe-legend-went-script-kissed-becky-lynch-live-tv: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/when-wwe-legend-went-script-kissed-becky-lynch-live-tv\n",
      "Failed to scrape content from https://www.sportskeeda.com/college-football/news-kyron-drones-injury-update-virginia-tech-coach-shares-current-status-hokies-qb: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/college-football/news-kyron-drones-injury-update-virginia-tech-coach-shares-current-status-hokies-qb\n",
      "Failed to scrape content from https://www.sportskeeda.com/aew/news-aew-creates-buzz-mysterious-trademark-filing: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/aew/news-aew-creates-buzz-mysterious-trademark-filing\n",
      "Failed to scrape content from https://www.sportskeeda.com/baseball/news-are-paying-kike-hernandez-minimum-wage-should-run-president-fans-amused-dodgers-star-serves-fans-food-celebrate-world-series-win: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/baseball/news-are-paying-kike-hernandez-minimum-wage-should-run-president-fans-amused-dodgers-star-serves-fans-food-celebrate-world-series-win\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/news-joe-burrow-explains-upset-despite-251-yard-5-td-performance-routing-raiders: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/news-joe-burrow-explains-upset-despite-251-yard-5-td-performance-routing-raiders\n",
      "Failed to scrape content from https://www.sportskeeda.com/us/olympics/news-simone-biles-drops-two-word-reaction-gold-over-america-tour-gymnast-yul-moldauer-s-heartfelt-note-upon-conclusion-shows: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/us/olympics/news-simone-biles-drops-two-word-reaction-gold-over-america-tour-gymnast-yul-moldauer-s-heartfelt-note-upon-conclusion-shows\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/news-did-daniel-jones-tell-teammates-vote-debunking-viral-myth-giants-qb: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/news-did-daniel-jones-tell-teammates-vote-debunking-viral-myth-giants-qb\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-sami-zayn-shares-two-word-message-ahead-potential-og-bloodline-reunion-wwe-smackdown: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-sami-zayn-shares-two-word-message-ahead-potential-og-bloodline-reunion-wwe-smackdown\n",
      "Failed to scrape content from https://www.sportskeeda.com/baseball/news-shohei-ohtani-injury-update-dodgers-star-undergoes-surgery-torn-left-labrum-expected-ready-spring-training: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/baseball/news-shohei-ohtani-injury-update-dodgers-star-undergoes-surgery-torn-left-labrum-expected-ready-spring-training\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/tee-higgins-injury-update-should-fantasy-managers-concerned-bengals-wr-week-10-fantasy-football: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/tee-higgins-injury-update-should-fantasy-managers-concerned-bengals-wr-week-10-fantasy-football\n",
      "Failed to scrape content from https://www.sportskeeda.com/aew/news-kenny-omega-blatantly-takes-shot-cm-punk-aew-brawl-scathing-rant: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/aew/news-kenny-omega-blatantly-takes-shot-cm-punk-aew-brawl-scathing-rant\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/news-tom-brady-makes-priorities-clear-stunned-ex-wife-gisele-bundchen-s-pregnancy-page-six-report: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/news-tom-brady-makes-priorities-clear-stunned-ex-wife-gisele-bundchen-s-pregnancy-page-six-report\n",
      "Failed to scrape content from https://www.sportskeeda.com/baseball/7-dodgers-now-free-agents-ft-jack-flaherty-teoscar-hernandez: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/baseball/7-dodgers-now-free-agents-ft-jack-flaherty-teoscar-hernandez\n",
      "Failed to scrape content from https://www.sportskeeda.com/baseball/news-i-thought-i-blown-oblique-out-freddie-freeman-rib-injury-scare-threatened-journey-dodgers-world-series-win: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/baseball/news-i-thought-i-blown-oblique-out-freddie-freeman-rib-injury-scare-threatened-journey-dodgers-world-series-win\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-seth-rollins-surprisingly-names-aew-star-one-favorite-opponents-wwe: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-seth-rollins-surprisingly-names-aew-star-one-favorite-opponents-wwe\n",
      "Failed to scrape content from https://www.sportskeeda.com/kabaddi/tamil-thalaivas-vs-telugu-titans-prediction-who-will-win-today-s-pkl-match-no-38: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/kabaddi/tamil-thalaivas-vs-telugu-titans-prediction-who-will-win-today-s-pkl-match-no-38\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-sami-zayn-sends-message-og-bloodline-confronting-the-usos-reacts-meeting-roman-reigns: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-sami-zayn-sends-message-og-bloodline-confronting-the-usos-reacts-meeting-roman-reigns\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/lamar-jackson-injury-update-should-fantasy-managers-concerned-ravens-qb-week-10-fantasy-football: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/lamar-jackson-injury-update-should-fantasy-managers-concerned-ravens-qb-week-10-fantasy-football\n",
      "Failed to scrape content from https://www.sportskeeda.com/basketball/news-lebron-james-fan-nba-analyst-says-4x-nba-champ-big-part-lakers-problem-amid-horrid-road-stretch: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/basketball/news-lebron-james-fan-nba-analyst-says-4x-nba-champ-big-part-lakers-problem-amid-horrid-road-stretch\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#add urls to this list to parse\n",
    "url_list = [\n",
    "        #MBFC High Credibility-9 (add 1 to cred.)\n",
    "        \"https://www.espn.com/espn/rss/news\", #ESPN top headlines\n",
    "        \"https://deadspin.com/rss/\", #Deadspin \n",
    "        \"https://feeds.abcnews.com/abcnews/sportsheadlines\" #ABC news- espn sports\n",
    "        \"https://rss.nytimes.com/services/xml/rss/nyt/Sports.xml\", #NYT\n",
    "        \"https://www.nytimes.com/athletic/rss/news/\"#The Athletic- acquired by NYT\n",
    "        \"https://www.mlb.com/feeds/news/rss.xml\", #MLB news \n",
    "        \"https://www.reutersagency.com/feed/?best-topics=sports&post_type=best\", # Reuters\n",
    "        \"https://sports.yahoo.com/rss/\", #Yahoo News\n",
    "        \"https://www.cbssports.com/rss/headlines/\" #CBS sports general headlines \n",
    "\n",
    "        #MBFC questionable sources or medium credibility- 5 (add -.5)\n",
    "        \"https://notthebee.com/feed\", #not the bee\n",
    "        \"https://uproxx.com/sports/feed/\", #uproxx   \n",
    "        \"https://www.vibe.com/c/news/sports/feed/\", #The vibe - medium cred \n",
    "        \"https://moxie.foxnews.com/google-publisher/sports.xml\", #fox news \n",
    "        \"https://nypost.com/sports/feed/\" #NY post - medium cred\n",
    "\n",
    "        #NO MBFC RATING -11 (add 0)\n",
    "        \"https://www.sportscollectorsdaily.com/feed/\", #Sports Collectors Daily \n",
    "        \"https://news.sportslogos.net/feed/\", #SportsLogos.Net\n",
    "        \"https://www.sportingnews.com/us/rss\", #sportingnews.com\n",
    "        \"https://www.sportskeeda.com/feed\",#sportskeeda.com\n",
    "        \"https://sportsweez.com/feed/\", #sportsweez\n",
    "        \"https://sportsbrackets.net/feed/\", #sportsbracket\n",
    "        \"https://21sports.com/feed/\", # 21 sports\n",
    "        \"https://www.essentiallysports.com/feed/\", #essentiallysports\n",
    "        \"https://boxingnewsonline.net/feed/\", #boxing news\n",
    "        \"https://www.thecoldwire.com/feed/\", #the cold wire\n",
    "        \"https://sportsdark.com/feed/\", #sports dark\n",
    "]\n",
    "    \n",
    "entries = [] #list of dictionaries\n",
    "\n",
    "#--------------DEFINE FUNCTION TO SCRAPE-------------------\n",
    "def scrape_article_content(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        #extract content from common tags\n",
    "        article_body = (\n",
    "            soup.find(\"article\") or\n",
    "            soup.find(\"div\", {\"class\": \"post-content\"}) or\n",
    "            soup.find(\"div\", class_=\"article-body\") or\n",
    "            soup.find(\"div\", class_=\"article-content\") or\n",
    "            soup.find(\"section\", class_=\"article-section\") or\n",
    "            soup.find(\"div\", class_=\"main-content\") or\n",
    "            soup.find(\"div\", class_=\"content-body\")\n",
    "        )\n",
    "        \n",
    "        if article_body:\n",
    "            paragraphs = article_body.find_all(\"p\")\n",
    "        else:\n",
    "            paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "        #join all paragraphs into a single string\n",
    "        article_content = \" \".join(p.get_text() for p in paragraphs)\n",
    "        return article_content.strip() if article_content else \"No content found\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape content from {url}: {e}\")\n",
    "        return \"Failed to fetch content\"\n",
    "\n",
    "\n",
    "#run the function to collect feeds and scrape\n",
    "for url in url_list:\n",
    "    feed = feedparser.parse(url)\n",
    "    #feed_title= feed.feed.title\n",
    "    feed_title = getattr(feed.feed, \"title\", None)\n",
    "\n",
    "    \n",
    "    for entry in feed.entries:\n",
    "        entry_title = getattr(entry, \"title\", None)\n",
    "        entry_link = getattr(entry, \"link\", None)\n",
    "        entry_published_date = getattr(entry, \"published\", None)\n",
    "        entry_summary = getattr(entry, \"summary\", None)\n",
    "        entry_content = scrape_article_content(entry_link) #scrape\n",
    "        \n",
    "        entries.append({\n",
    "            \"feed_title\": feed_title,\n",
    "            \"entry_title\": entry_title,\n",
    "            \"entry_link\": entry_link,\n",
    "            \"entry_published_date\": entry_published_date,\n",
    "            \"entry_summary\": entry_summary,\n",
    "            \"entry_content\": entry_content,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(entries)\n",
    "#print(df)\n",
    "\n",
    "df.to_csv('RSS_sports_feeds_11-20.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b17ce3-4167-4ee2-b75b-0e30f8d21697",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attempt to Scrape Links without RSS Feeds- not very effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9a3d96-4201-4150-8ecb-b14e133f886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# uncredible_urls = [\n",
    "#     \"https://www.tellerreport.com/sports\",\n",
    "#     \"https://www.newsbreak.com/mountain-view-ca-sports\",\n",
    "#     \"https://newsrnd.com/sports\",\n",
    "#     \"https://baltimorecitywire.com/stories/tag/53-sports\"\n",
    "# ]\n",
    "\n",
    "# # Function to scrape article details\n",
    "# def scrape_article(url):\n",
    "#     try:\n",
    "#         response = requests.get(url, timeout=10)\n",
    "#         response.raise_for_status()\n",
    "#         soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#         # Extract the article title\n",
    "#         title = soup.find(\"h1\").get_text() if soup.find(\"h1\") else soup.title.get_text()\n",
    "\n",
    "#         # Extract the publication date (common in <time> or meta tags)\n",
    "#         date = soup.find(\"time\")\n",
    "#         if date:\n",
    "#             publication_date = date.get(\"datetime\") or date.get_text()\n",
    "#         else:\n",
    "#             date_meta = soup.find(\"meta\", {\"name\": \"article:published_time\"})\n",
    "#             publication_date = date_meta[\"content\"] if date_meta else \"No date found\"\n",
    "\n",
    "#         # Extract the article content\n",
    "#         content_container = (\n",
    "#             soup.find(\"article\") or\n",
    "#             soup.find(\"div\", class_=[\"post-content\", \"article-body\", \"article-content\", \"content-body\"])\n",
    "#         )\n",
    "#         if content_container:\n",
    "#             paragraphs = content_container.find_all(\"p\")\n",
    "#         else:\n",
    "#             paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "#         content = \"\\n\".join(p.get_text() for p in paragraphs)\n",
    "\n",
    "#         return {\n",
    "#             \"Title\": title.strip(),\n",
    "#             \"Publication Date\": publication_date.strip(),\n",
    "#             \"Content\": content.strip()[:500] + \"...\",\n",
    "#             \"Link\": url\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to scrape {url}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# articles = []\n",
    "# for url in uncredible_urls:\n",
    "#     print(f\"Scraping: {url}\")\n",
    "#     article_details = scrape_article(url)\n",
    "#     if article_details:\n",
    "#         articles.append(article_details)\n",
    "\n",
    "# for article in articles:\n",
    "#     print(\"\\n--- Article ---\")\n",
    "#     print(f\"Title: {article['Title']}\")\n",
    "#     print(f\"Date: {article['Publication Date']}\")\n",
    "#     print(f\"Content Preview: {article['Content']}\")\n",
    "#     print(f\"Link: {article['Link']}\\n\")\n",
    "\n",
    "# df = pd.DataFrame(articles)\n",
    "# output_file = \"scraped_uncredible_articles.csv\"\n",
    "# df.to_csv(output_file, index=False)\n",
    "# print(f\"\\nResults saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f53448-164e-46d8-a16d-02c3dbaa7d0c",
   "metadata": {},
   "source": [
    "### Format DF to match DB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b6b1163a-ce9f-47f0-9c15-d7e5cceaf6e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tizia\\Anaconda4\\Lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "df['publication_date'] = df['entry_published_date'].apply(lambda x: parser.parse(x).date()) #parse different date formats to date object format\n",
    "dbdf = pd.read_csv('RSS_sports_feeds.csv')\n",
    "dbdf['team_or_player'] = df['entry_title']\n",
    "dbdf['source'] = df['feed_title']\n",
    "dbdf['publication_date'] = df['publication_date'] \n",
    "dbdf['content'] = df['entry_summary']\n",
    "dbdf['trust_score'] = 0.00  #default\n",
    "dbdf['classification'] = 'unknown' #default\n",
    "dbdf['link'] = df['entry_link']\n",
    "\n",
    "#make a new df in the format of the DB table for easy inserting\n",
    "sports_DB_df = dbdf[['team_or_player', 'source', 'publication_date', 'content', 'trust_score', 'classification', 'link']]\n",
    "#save to a new CSV \n",
    "sports_DB_df.to_csv('formatted_sports_posts_for_DB.csv', index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b923503-bb70-46cc-ad0c-a13fb1dbdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_euro_df = pd.read_csv('real_european.csv')\n",
    "fake_euro_df = pd.read_csv('fake_european.csv')\n",
    "\n",
    "real_euro_df[\"label\"] = \"True\"\n",
    "fake_euro_df[\"label\"] = \"False\"\n",
    "\n",
    "real_tweets= real_euro_df[\"tweet\"].dropna()\n",
    "fake_tweets= fake_euro_df[\"tweet\"].dropna()\n",
    "\n",
    "# Compute features for true and false tweets\n",
    "euro_true_features_df = compute_features(real_tweets)\n",
    "euro_false_features_df = compute_features(fake_tweets)\n",
    "\n",
    "euro_true_features_df[\"label\"] = \"True\"\n",
    "euro_false_features_df[\"label\"] = \"False\"\n",
    "\n",
    "euro_combined_df = pd.concat([euro_true_features_df, euro_false_features_df], ignore_index=True)\n",
    "euro_combined_df.to_csv(\"Euro_tweets_initial_hueristic_exploration.csv\")\n",
    "print(\"Data saved to 'Euro_tweets_initial_hueristic_exploration.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282d88e-3a8a-4283-af31-f011ec789135",
   "metadata": {},
   "source": [
    "### Define labeling heuristic and trust score to update sports_DB_df with ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a5014-fff8-4491-a937-cadbd2b697ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
