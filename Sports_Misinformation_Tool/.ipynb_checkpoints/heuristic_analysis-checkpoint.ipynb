{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd962a0-9c5c-47c5-82c9-618b80b923c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Lists\n",
    "false_headlines=[\n",
    "    \"BREAKING: Fox Sports Cancels ALL NFL Broadcasts \\\"Until Players Respect The Flag\\\"\",\n",
    "    \"Rugby Safer Than American Football \\\"For Health Reasons\\\": Biden\",\n",
    "    \"First woman to medal in six straight Olympics. Media and sponsors ignore her because she is outspoken pro-2A.\",\n",
    "    \"Novak Djokovic becomes the first professional athlete in history to be banned from a major sporting competition for not taking drugs\",\n",
    "    \"BREAKING: ESPN has fired Shannon Sharpe, per @ESPNNBA\",\n",
    "    \"The Minnesota Vikings have denounced Tim Walz: \\\"We don’t suppᴏrt his values.\\\"\",\n",
    "    \"'BREAKING: WNBA referees disqualify two players under league’s new \\\"no anthem kneeling\\\" rule\",\n",
    "    \"Nike announces termination of contract with Brittney Griner after \\\"strong backlash\\\" from online community: \\\"We need more athletes like Riley Gaines and less woke Brittney Griner!\\\"\",\n",
    "    \"KNEELING: After the University of Texas, all students who knelt during the national anthem were rounded up and REMOVED FROM SCHOLARSHIPS\",\n",
    "    \"Travis Kelce kneels during national anthem fined $10 million and thrown out of the game.\",\n",
    "    \"The NFL will now use facial recognition at every stadium to verify the identity of everyone at the game.\",\n",
    "    \"Mike Tyson says he’s willing to box Olympic DUDE with all proceeds to go to a battered women’s charity.\",\n",
    "    \"After winning silver, Yusef stood emotionless on the Olympic podium and declared, \\\"Sharon, if you’re watching this, I want my dog back.\\\"\",\n",
    "    \"Miami Dolphins QB Tua Tagovailoa will be sitting front row tonight in Doral for the Trump speech\",\n",
    "    \"BREAKING: The WNBA organizers have officially announced an investigation into the referees in all of Caitlin Clark's games for ignoring all dirty actions by her opponents against her\",\n",
    "    \"Chiefs' Coach Andy Reid \\\"fires 3 top players for anthem kneeling.\\\"\",\n",
    "    \"BREAKING: Caitlin Clark Rejects $400 Million Deal From Nike, \\\"Not With That Kaepernick Clown,\\\"\",\n",
    "    \"At Euro 2020, UEFA (European Football Association) ordered all team captains to wear \\\"OneLove\\\" bands. The band was used as a symbol of LGBTQ. But, Portugal captain Cristiano Ronaldo was the only European captain who did not wear the band.\",\n",
    "    \"Golden State Warriors refuse to visit White House after winning NBA title: reports\",\n",
    "    \"Taylor Swift faces a 10-game NFL ban following controversial political involvement - fans in uproar!\"\n",
    "]\n",
    "true_headlines=[\n",
    "    \"Did that really happen? Barbados v Grenada and a deliberate own goal\",\n",
    "    \"Breakdancing Will Not Be Busting A Move In 2028 Olympics\",\n",
    "    \"Breaking Will Not Be in The 2028 Los Angeles Olympics—What’s Next?\",\n",
    "    \"Braves Superstar Sets Atlanta-Era Record in 1st Inning\",\n",
    "    \"Only 20 schools in the Football Bowl Subdivision have athletic departments with revenue exceeding expenses\",\n",
    "    \"LATEST: Mitchell Stadium named America’s Best High School Football Stadium\",\n",
    "    \"Homes of Patrick Mahomes, Travis Kelce burglarized last month\",\n",
    "    \"Gregg Popovich recovering from mild stroke, no timeline for return set\",\n",
    "    \"Patrick Queen: I wasn’t wanted back with Ravens, it was definitely kind of upsetting\",\n",
    "    \"Odell Beckham Jr. boasts about taking 2021 Rams salary in Bitcoin National Football League Odell Beckham Jr. boasts about taking 2021 Rams salary in Bitcoin\",\n",
    "    \"Ecuador international soccer player Marco Angulo dies aged 22 following car crash\",\n",
    "    \"Shohei Ohtani Baseball Worth $4 Million Lands in Globally-Recognized Skyscraper\",\n",
    "    \"Kobe Bryant is the only person to have won both an Olympic medal and an Oscar\",\n",
    "    \"Bucks fan predicted Milwaukee-Phoenix NBA Finals all the way back in 2016\",\n",
    "    \"Chiefs kicker Butker congratulates women graduates and says most are more excited about motherhood\",\n",
    "    \"Kansas City Chiefs player faces backlash for graduation speech criticizing working women, calling Pride a \\\"deadly sin\\\"\", \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2cb704-6e6b-4528-946e-0a06fd2c7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textstat\n",
    "from transformers import pipeline\n",
    "import string\n",
    "from textstat import flesch_reading_ease\n",
    "import textstat\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "#functions for each feature we are considering\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def char_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def avg_word_length(text):\n",
    "    words = text.split()\n",
    "    return sum(len(word) for word in words) / len(words) if words else 0\n",
    "\n",
    "def all_capitalized_word_count(text):\n",
    "    return sum(1 for word in text.split() if word.isupper())\n",
    "\n",
    "def punctuation_count(text):\n",
    "    return sum(1 for char in text if char in string.punctuation)\n",
    "\n",
    "def exclamation_count(text):\n",
    "    return text.count(\"!\")\n",
    "\n",
    "def question_mark_count(text):\n",
    "    return text.count(\"?\")\n",
    "\n",
    "def readability_score(text): #high score = easier readability\n",
    "    return flesch_reading_ease(text)\n",
    "\n",
    "def smog_index(text): #readability based on the number of complex words (3+ syllables)\n",
    "    return textstat.smog_index(text)\n",
    "\n",
    "def count_quotation_pairs(text): \n",
    "    double_quotes = re.findall(r'\"[^\"]+\"', text) #Finds all sections of text in double quotes\n",
    "    return len(double_quotes)\n",
    "\n",
    "def variety_of_vocabularity(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words) / len(words) if words else 0\n",
    "\n",
    "\n",
    "sensational_words = [\"shocking\",\"shock\", \"amazing\", \"unbelievable\", \"you won’t believe\", \"incredible\", \"stunning\",\\\n",
    "                    \"astounding\", \"breathtaking\", \"outstanding\", \"thrilling\", \"must see\", \"terrible\", \"awful\",\\\n",
    "                     \"fantastic\", \"horrible\", \"remarkable\"]\n",
    "def count_sensational_words(text):\n",
    "    text = text.lower()\n",
    "    return sum(1 for word in sensational_words if word in text)\n",
    "\n",
    "\n",
    "absolute_words = [\"always\", \"never\", \"clearly\", \"obviously\", \"definitely\", \"everyone\", \"nobody\", \"all\",\\\n",
    "              \"none\", \"blatantly\", \"undoubtedly\", \"must\", \"should\"]\n",
    "def count_absolute_words(text):\n",
    "    words = text.lower().split()\n",
    "    return sum(1 for word in words if word in absolute_words)\n",
    "\n",
    "\n",
    "factuality_words = [\"proven\", \"irrefutable\", \"unarguable\", \"unquestionably\", \"certainly\", \"definitely\",\\\n",
    "                    \"undeniable\"]\n",
    "def count_factuality_words(text):\n",
    "    words = text.lower().split()\n",
    "    return sum(1 for word in words if word in factuality_words)\n",
    "\n",
    "\n",
    "subjective_words = [\"believe\", \"think\", \"feel\", \"prefer\", \"seems\", \"wish\"]\n",
    "def subjectivity_score(text):\n",
    "    words = text.lower().split()\n",
    "    subjective_count = sum(1 for word in words if word in subjective_words)\n",
    "    return subjective_count / len(words) if len(words) > 0 else 0\n",
    "\n",
    "objective_words = [\"reported\", \"measured\", \"confirmed\", \"analyzed\", \"observed\", \"recorded\",\\\n",
    "                   \"found\", \"documented\", \"verified\", \"tested\", \"studied\", \"calculated\", \"noted\",\\\n",
    "                   \"established\", \"evidence\", \"fact\", \"data\", \"statistics\", \"demonstrated\", \"shown\",\\\n",
    "                   \"results\", \"result\", \"evidence-based\", \"peer-reviewed\", \"sampled\", \"quantified\",\\\n",
    "                   \"evaluated\", \"experimented\", \"investigated\"]\n",
    "def objective_score(text):\n",
    "    words = text.lower().split()\n",
    "    objective_count = sum(1 for word in words if word in objective_words)\n",
    "    return objective_count / len(words) if len(words) > 0 else 0\n",
    "\n",
    "\n",
    "def count_numerics(text):\n",
    "    numerical_count = len(re.findall(r'\\d+', text)) \n",
    "    return numerical_count\n",
    "\n",
    "\n",
    "pipe_finnews = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "def sentiment(text):\n",
    "    result = pipe_finnews(text)\n",
    "    return result[0][\"label\"] \n",
    "\n",
    "    \n",
    "#add in source credibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e113df98-a3ba-4de0-bc7e-83fb21aba9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'headlines_initial_hueristic_exploration.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Apply these feature functions to the headlines to compare\n",
    "features = [\n",
    "    word_count, char_count, avg_word_length, all_capitalized_word_count,\n",
    "    punctuation_count, exclamation_count, question_mark_count, readability_score,\n",
    "    smog_index, count_quotation_pairs, variety_of_vocabularity,\n",
    "    count_sensational_words, count_absolute_words, count_factuality_words,\n",
    "    subjectivity_score, objective_score, count_numerics, sentiment,\n",
    "]\n",
    "\n",
    "def compute_features(headlines):\n",
    "    results = []\n",
    "    for headline in headlines:\n",
    "        data = {\n",
    "            \"headline\": headline,\n",
    "            \"word_count\": word_count(headline),\n",
    "            \"char_count\": char_count(headline),\n",
    "            \"avg_word_length\": avg_word_length(headline),\n",
    "            \"all_capitalized_word_count\": all_capitalized_word_count(headline),\n",
    "            \"punctuation_count\": punctuation_count(headline),\n",
    "            \"exclamation_count\": exclamation_count(headline),\n",
    "            \"question_mark_count\": question_mark_count(headline),\n",
    "            \"readability_score\": readability_score(headline),\n",
    "            \"smog_index\": smog_index(headline),\n",
    "            \"quotation_count\": count_quotation_pairs(headline),\n",
    "            \"vocab_variety\": variety_of_vocabularity(headline),\n",
    "            \"sensational_words_count\": count_sensational_words(headline),\n",
    "            \"absolute_words_count\": count_absolute_words(headline),\n",
    "            \"factuality_words_count\": count_factuality_words(headline),\n",
    "            \"subjectivity_score\": subjectivity_score(headline),\n",
    "            \"objective_score\": objective_score(headline),\n",
    "            \"count_numerics\": count_numerics(headline),\n",
    "            \"sentiment\": sentiment(headline),\n",
    "        }\n",
    "        results.append(data)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "true_features_df = compute_features(true_headlines)\n",
    "false_features_df = compute_features(false_headlines)\n",
    "\n",
    "true_features_df[\"label\"] = \"True\"\n",
    "false_features_df[\"label\"] = \"False\"\n",
    "\n",
    "combined_df = pd.concat([true_features_df, false_features_df], ignore_index=True)\n",
    "combined_df.to_csv(\"headlines_initial_hueristic_exploration.csv\")\n",
    "print(\"Data saved to 'headlines_initial_hueristic_exploration.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0fcfb20-7975-4269-8ce6-e476deef6b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             True_Avg   False_Avg\n",
      "word_count                  12.875000   17.650000\n",
      "char_count                  82.562500  110.450000\n",
      "avg_word_length              5.543158    5.370848\n",
      "all_capitalized_word_count   0.250000    1.150000\n",
      "punctuation_count            1.000000    3.200000\n",
      "exclamation_count            0.000000    0.100000\n",
      "question_mark_count          0.125000    0.000000\n",
      "readability_score           60.378750   61.347000\n",
      "smog_index                   0.400000    0.485000\n",
      "quotation_count              0.062500    0.500000\n",
      "vocab_variety                0.962344    0.976598\n",
      "sensational_words_count      0.000000    0.000000\n",
      "absolute_words_count         0.125000    0.350000\n",
      "factuality_words_count       0.062500    0.000000\n",
      "subjectivity_score           0.000000    0.000000\n",
      "objective_score              0.000000    0.000000\n",
      "count_numerics               0.562500    0.300000\n"
     ]
    }
   ],
   "source": [
    "#compare the averages of the numeric features \n",
    "true_avg_features = true_features_df.mean(numeric_only=True).to_dict()\n",
    "false_avg_features = false_features_df.mean(numeric_only=True).to_dict()\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"True_Avg\": true_avg_features,\n",
    "    \"False_Avg\": false_avg_features\n",
    "})\n",
    "\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f80a1-a68d-41ee-aa77-3b1d9547aea0",
   "metadata": {},
   "source": [
    "### Run the Heuristics on the European Soccer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30794b-66c6-4268-9990-cbda5ebbe110",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_euro_df = pd.read_csv('real_european.csv')\n",
    "fake_euro_df = pd.read_csv('fake_european.csv')\n",
    "\n",
    "real_euro_df[\"label\"] = \"True\"\n",
    "fake_euro_df[\"label\"] = \"False\"\n",
    "\n",
    "real_tweets= real_euro_df[\"tweet\"].dropna()\n",
    "fake_tweets= fake_euro_df[\"tweet\"].dropna()\n",
    "\n",
    "euro_true_features_df = compute_features(real_tweets)\n",
    "euro_false_features_df = compute_features(fake_tweets)\n",
    "\n",
    "euro_true_features_df[\"label\"] = \"True\"\n",
    "euro_false_features_df[\"label\"] = \"False\"\n",
    "\n",
    "euro_combined_df = pd.concat([euro_true_features_df, euro_false_features_df], ignore_index=True)\n",
    "euro_combined_df.to_csv(\"Euro_tweets_initial_hueristic_exploration.csv\")\n",
    "print(\"Data saved to 'Euro_tweets_initial_hueristic_exploration.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "59268638-6dc4-4711-b252-c9a935994377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sample\n",
    "df = pd.read_csv(\"Euro_tweets_initial_hueristic_exploration.csv\")\n",
    "\n",
    "true_samples = df[df[\"label\"] == True].sample(n=200,random_state=42 )\n",
    "false_samples = df[df[\"label\"] == False].sample(n=200,random_state=42)\n",
    "\n",
    "sampled_df = pd.concat([true_samples, false_samples])\n",
    "\n",
    "sampled_df.to_csv(\"Euro_tweets_initial_hueristic_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7898dad9-7344-4fe3-9bd1-17074c629158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                True_Avg     False_Avg\n",
      "Unnamed: 0                  10555.865000  32670.315000\n",
      "word_count                     26.690000     25.025000\n",
      "char_count                    165.945000    140.080000\n",
      "avg_word_length                 5.370402      6.088673\n",
      "all_capitalized_word_count      0.000000      0.000000\n",
      "punctuation_count               5.920000      4.990000\n",
      "exclamation_count               0.040000      0.110000\n",
      "question_mark_count             0.105000      0.170000\n",
      "readability_score              52.313700     67.755650\n",
      "smog_index                      0.146000      1.274000\n",
      "quotation_count                 0.040000      0.030000\n",
      "vocab_variety                   0.873336      0.882697\n",
      "sensational_words_count         0.000000      0.000000\n",
      "absolute_words_count            0.035000      0.090000\n",
      "factuality_words_count          0.000000      0.010000\n",
      "subjectivity_score              0.000601      0.002782\n",
      "objective_score                 0.001055      0.001103\n",
      "count_numerics                  0.850000      0.255000\n",
      "label                           1.000000      0.000000\n"
     ]
    }
   ],
   "source": [
    "#compare the averages of the numeric features \n",
    "\n",
    "euro_true_avg_features = true_samples.mean(numeric_only=True).to_dict()\n",
    "euro_false_avg_features = false_samples.mean(numeric_only=True).to_dict()\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"True_Avg\": euro_true_avg_features,\n",
    "    \"False_Avg\": euro_false_avg_features\n",
    "})\n",
    "\n",
    "print(comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
