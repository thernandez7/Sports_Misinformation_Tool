{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72517dfa-1720-49e6-b55a-f15cdf181498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/SportsNewsTool-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/SportsNewsTool.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 20d6ab6] added feature calculation functions\n",
      " 4 files changed, 538 insertions(+), 464 deletions(-)\n",
      " delete mode 100644 Sports_Misinformation_Tool/.ipynb_checkpoints/Analysis_for Heuristic-checkpoint.ipynb\n",
      " delete mode 100644 Sports_Misinformation_Tool/Analysis_for Heuristic.ipynb\n",
      "Already up to date.\n",
      "branch 'main' set up to track 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:thernandez7/Sports_Misinformation_Tool.git\n",
      "   be7bc15..20d6ab6  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"ran RSS Feed and updated combined csv, also added features\"\n",
    "!git pull\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446acb8-a93e-418e-a0ec-3ef05f7389b8",
   "metadata": {},
   "source": [
    "## Sports Misinformation Classification Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e525a-1cf9-47be-8298-238a25ce2667",
   "metadata": {},
   "source": [
    "### Connect to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc105918-5fb3-432a-b47f-f3717be38100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fde6c4b-1920-4bb2-846f-61455f869aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully!\n"
     ]
    }
   ],
   "source": [
    "username = 'root'  \n",
    "password = 'password'\n",
    "host = 'localhost' \n",
    "database = 'sports_news_db'\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host=host,\n",
    "    user=username,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "if connection.is_connected():\n",
    "    print(\"Connected to the database successfully!\")\n",
    "\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{username}:{password}@{host}/{database}\", echo=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70ed146f-9fe7-4370-a3d2-898811f3e183",
   "metadata": {},
   "source": [
    "#### Use this format to insert into the database\n",
    "\n",
    "INSERT INTO articles (team_or_player, source, publication_date, content, trust_score, classification, link)\n",
    "VALUES\n",
    "('New York Yankees, Los Angeles Lakers', 'ESPN', '2024-10-27', 'Yankees article content example.', 85.00, 'real', 'https://example.com/article1'),\n",
    "('Los Angeles Lakers', 'Twitter', '2024-10-27', 'Lakers article content example.', 60.00, 'fake', 'https://example.com/article2');\n",
    "\n",
    "\n",
    "#### Table fields \n",
    "Table Name: articles\n",
    "\n",
    "Fields: \n",
    "\n",
    "     id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "     \n",
    "     team_or_player VARCHAR(500), (This will be the article title that we can query- usually includes teams or names in it)\n",
    "     \n",
    "     source VARCHAR(200),\n",
    "     \n",
    "     publication_date DATE,\n",
    "     \n",
    "     content TEXT,\n",
    "     \n",
    "     trust_score DECIMAL(5, 2), \n",
    "     \n",
    "     classification ENUM('credible', 'uncredible', 'unknown') DEFAULT 'unknown',\n",
    "\n",
    "     link VARCHAR(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359168cc-f336-4972-b580-38575b45a13e",
   "metadata": {},
   "source": [
    "### Simulate Tool Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9687e8d1-8c66-4df1-80cf-4bcf6f33805c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the team or player's name:  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No articles found for x.\n"
     ]
    }
   ],
   "source": [
    "team_or_player = input(\"Enter the team or player's name: \")\n",
    "\n",
    "query = f\"SELECT * FROM articles WHERE team_or_player LIKE '%{team_or_player}%'\" #search for entered name/team in the title \n",
    "df_result = pd.read_sql(query, con=engine, params={'team_or_player': team_or_player})\n",
    "\n",
    "#get results\n",
    "if not df_result.empty:\n",
    "    print(f\"Articles related to {team_or_player}:\")\n",
    "    display(df_result)\n",
    "else:\n",
    "    print(f\"No articles found for {team_or_player}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cee353-47af-48c3-a0eb-cf19ddcbc995",
   "metadata": {},
   "source": [
    "### Get Article Entries from RSS Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ea0136-a9b1-4fac-94f6-1949deec9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reddit API - collected 1876 posts\n",
    "# import csv\n",
    "# import praw\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "# reddit = praw.Reddit(\n",
    "#     client_id='w-kwRyPigyjYeG9DOiDc8g', \n",
    "#     client_secret='ZeDsvNH2YlpVH7F9wEWPkt5wkjLzqA',  \n",
    "#     user_agent='sports_misinfo_script'  \n",
    "# )\n",
    "\n",
    "# subreddit = reddit.subreddit('sports+fantasyfootball') #2 subreddits \n",
    "\n",
    "# recent_posts = []\n",
    "# for post in subreddit.new(limit= 5000):\n",
    "#     created_date = datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "#     recent_posts.append({\n",
    "#         'title': post.title,\n",
    "#         'score': post.score,\n",
    "#         'url': post.url,\n",
    "#         'id': post.id,\n",
    "#         'author': str(post.author),\n",
    "#         'text': post.selftext,\n",
    "#         'created_date': created_date,\n",
    "#         'num_comments': post.num_comments,\n",
    "#         'subreddit': post.subreddit.display_name,\n",
    "\n",
    "#     })\n",
    "\n",
    "# print(f\"Fetched {len(recent_posts)} posts\")\n",
    "\n",
    "# for i, post in enumerate(recent_posts[:5]):\n",
    "#     print(f\"{i+1}. Title: {post['title']} | Score: {post['score']} | URL: {post['url']}\")\n",
    "\n",
    "\n",
    "# #-------------------------------\n",
    "# #Save the data to a csv file\n",
    "# fieldnames = ['title', 'score', 'url', 'id', 'author', 'text', 'created_date', 'num_comments', 'subreddit']\n",
    "\n",
    "# with open('recent_sports_reddit_posts.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "#     writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "#     writer.writeheader()\n",
    "\n",
    "#     for post in recent_posts:\n",
    "#         writer.writerow(post)\n",
    "\n",
    "# print(\"Data successfully saved to 'recent_sports_reddit_posts.csv'\")\n",
    "# print(\"Data saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "334d2970-7ee0-47e1-80d9-e01ae15fa4a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to scrape content from https://www.espn.com/nba/story/_/id/42429171/draymond-green-trip-zach-edey-upgraded-flagrant-1: 403 Client Error: Forbidden for url: https://www.espn.com/nba/story/_/id/42429171/draymond-green-trip-zach-edey-upgraded-flagrant-1\n",
      "Failed to scrape content from https://www.espn.com/boxing/story/_/id/42431417/netflix-says-60m-households-worldwide-watched-paul-tyson: 403 Client Error: Forbidden for url: https://www.espn.com/boxing/story/_/id/42431417/netflix-says-60m-households-worldwide-watched-paul-tyson\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42432389/shedeur-sanders-colorado-buffaloes-dominate-utah-utes-49-24: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42432389/shedeur-sanders-colorado-buffaloes-dominate-utah-utes-49-24\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42430467/ohio-state-wr-carnell-tate-scores-2-tds-emotional-homecoming: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42430467/ohio-state-wr-carnell-tate-scores-2-tds-emotional-homecoming\n",
      "Failed to scrape content from https://www.espn.com/wnba/story/_/id/42431565/source-storm-investigating-coaches-alleged-player-mistreatment: 403 Client Error: Forbidden for url: https://www.espn.com/wnba/story/_/id/42431565/source-storm-investigating-coaches-alleged-player-mistreatment\n",
      "Failed to scrape content from https://www.espn.com/nba/story/_/id/42432063/doc-rivers-laments-refs-blowing-call-late-bucks-loss: 403 Client Error: Forbidden for url: https://www.espn.com/nba/story/_/id/42432063/doc-rivers-laments-refs-blowing-call-late-bucks-loss\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42423807/sources-curt-cignetti-gets-new-deal-indiana-10-0-start: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42423807/sources-curt-cignetti-gets-new-deal-indiana-10-0-start\n",
      "Failed to scrape content from https://www.espn.com/tennis/story/_/id/42426096/taylor-fritz-reaches-atp-finals-title-match-win-zverev: 403 Client Error: Forbidden for url: https://www.espn.com/tennis/story/_/id/42426096/taylor-fritz-reaches-atp-finals-title-match-win-zverev\n",
      "Failed to scrape content from https://www.espn.com/mma/story/_/id/42292589/ufc-309-jon-jones-vs-stipe-miocic-live-results-analysis: 403 Client Error: Forbidden for url: https://www.espn.com/mma/story/_/id/42292589/ufc-309-jon-jones-vs-stipe-miocic-live-results-analysis\n",
      "Failed to scrape content from https://www.espn.com/mma/story/_/id/42388257/ranking-fights-ufc-309-jon-jones-vs-stipe-miocic-leads-way: 403 Client Error: Forbidden for url: https://www.espn.com/mma/story/_/id/42388257/ranking-fights-ufc-309-jon-jones-vs-stipe-miocic-leads-way\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42391146/tennessee-volunteers-recruiting-built-dl-beat-georgia-bulldogs: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42391146/tennessee-volunteers-recruiting-built-dl-beat-georgia-bulldogs\n",
      "Failed to scrape content from https://www.espn.com/boxing/story/_/id/42419370/after-mike-tyson-jake-paul-surprised-see-boxing-spectacle-again: 403 Client Error: Forbidden for url: https://www.espn.com/boxing/story/_/id/42419370/after-mike-tyson-jake-paul-surprised-see-boxing-spectacle-again\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/page/nflviewguide-42388677/nfl-week-11-picks-schedule-fantasy-football-odds-injuries-stats-2024: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/page/nflviewguide-42388677/nfl-week-11-picks-schedule-fantasy-football-odds-injuries-stats-2024\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42428167/washington-spirit-gotham-fc-shootout-nwsl-semifinal-championship: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42428167/washington-spirit-gotham-fc-shootout-nwsl-semifinal-championship\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42430199/usmnt-tim-ream-tim-weah-back-copa-america-red-card: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42430199/usmnt-tim-ream-tim-weah-back-copa-america-red-card\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42423254/cristiano-ronaldo-makes-retirement-hint-record-portugal-win: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42423254/cristiano-ronaldo-makes-retirement-hint-record-portugal-win\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42425280/bayern-munich-extend-mala-grohs-contract-cancer-diagnosis: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42425280/bayern-munich-extend-mala-grohs-contract-cancer-diagnosis\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42425119/ireland-vs-england-harry-kane-warns-camp-culture-fragility: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42425119/ireland-vs-england-harry-kane-warns-camp-culture-fragility\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42418031/mexico-coach-aguirre-hit-head-beer-loss-honduras: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42418031/mexico-coach-aguirre-hit-head-beer-loss-honduras\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42427478/man-united-confirm-ruben-amorim-coaching-staff: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42427478/man-united-confirm-ruben-amorim-coaching-staff\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42413663/kosovo-romania-uefa-nations-league-abandoned-serbia: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42413663/kosovo-romania-uefa-nations-league-abandoned-serbia\n",
      "Failed to scrape content from https://www.espn.com/espn/betting/story/_/id/42376299/2024-nfl-season-betting-odds-daniel-dopp-liz-loza-football-props-pop-week-11: 403 Client Error: Forbidden for url: https://www.espn.com/espn/betting/story/_/id/42376299/2024-nfl-season-betting-odds-daniel-dopp-liz-loza-football-props-pop-week-11\n",
      "Failed to scrape content from https://www.espn.com/espn/betting/story/_/id/42394173/2024-nba-betting-futures-rookie-year-jared-mccain-zaccharie-risacher-zach-edey: 403 Client Error: Forbidden for url: https://www.espn.com/espn/betting/story/_/id/42394173/2024-nba-betting-futures-rookie-year-jared-mccain-zaccharie-risacher-zach-edey\n",
      "Failed to scrape content from https://www.espn.com/boxing/story/_/id/42422294/katie-taylor-amanda-serrano-jake-paul-mike-tyson-boxing: 403 Client Error: Forbidden for url: https://www.espn.com/boxing/story/_/id/42422294/katie-taylor-amanda-serrano-jake-paul-mike-tyson-boxing\n",
      "Failed to scrape content from https://www.espn.com/wnba/story/_/id/42370750/wnba-mock-draft-2025-paige-bueckers-draft-lottery-los-angeles-sparks-dallas-wings-washington-mystics-chicago-sky: 403 Client Error: Forbidden for url: https://www.espn.com/wnba/story/_/id/42370750/wnba-mock-draft-2025-paige-bueckers-draft-lottery-los-angeles-sparks-dallas-wings-washington-mystics-chicago-sky\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42431717/soccer-transfer-rumors-news-lafc-circle-griezmann-eyes-atleti-exit: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42431717/soccer-transfer-rumors-news-lafc-circle-griezmann-eyes-atleti-exit\n",
      "Failed to scrape content from https://www.espn.com/mens-college-basketball/story/_/id/42391361/judging-5-early-season-mens-college-basketball-overreactions-kentucky-flagg-arkansas: 403 Client Error: Forbidden for url: https://www.espn.com/mens-college-basketball/story/_/id/42391361/judging-5-early-season-mens-college-basketball-overreactions-kentucky-flagg-arkansas\n",
      "Failed to scrape content from https://www.espn.com/mens-college-basketball/story/_/id/42371393/mens-college-basketball-power-rankings-2024-25-kansas-gonzaga-auburn-kentucky: 403 Client Error: Forbidden for url: https://www.espn.com/mens-college-basketball/story/_/id/42371393/mens-college-basketball-power-rankings-2024-25-kansas-gonzaga-auburn-kentucky\n",
      "Failed to scrape content from https://www.espn.com/nhl/story/_/id/42390646/nhl-power-rankings-2024-2025-best-teams-standings-fantasy-hockey: 403 Client Error: Forbidden for url: https://www.espn.com/nhl/story/_/id/42390646/nhl-power-rankings-2024-2025-best-teams-standings-fantasy-hockey\n",
      "Failed to scrape content from https://www.espn.com/nfl/draft2025/story/_/id/42352442/2025-nfl-draft-top-pick-panthers-jaguars-raiders-giants-patriots-titans: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/draft2025/story/_/id/42352442/2025-nfl-draft-top-pick-panthers-jaguars-raiders-giants-patriots-titans\n",
      "Failed to scrape content from https://www.sportskeeda.com/us/movies/the-black-phone-2-everything-know-far: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/us/movies/the-black-phone-2-everything-know-far\n",
      "Failed to scrape content from https://www.sportskeeda.com/basketball/news-is-anthony-davis-playing-tonight-memphis-grizzlies-latest-injury-update-mvp-candidate-nov-6: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/basketball/news-is-anthony-davis-playing-tonight-memphis-grizzlies-latest-injury-update-mvp-candidate-nov-6\n",
      "Failed to scrape content from https://www.sportskeeda.com/esports/zenless-zone-zero-zzz-the-mystery-arpeggio-fault-event-guide: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/esports/zenless-zone-zero-zzz-the-mystery-arpeggio-fault-event-guide\n",
      "Failed to scrape content from https://www.sportskeeda.com/mma/news-adriano-moraes-wants-reece-mclaren-fight-vacant-flyweight-gold-the-fight-make: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/mma/news-adriano-moraes-wants-reece-mclaren-fight-vacant-flyweight-gold-the-fight-make\n",
      "Failed to scrape content from https://www.sportskeeda.com/roblox-news/how-earn-christmas-cookies-anime-defenders: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/roblox-news/how-earn-christmas-cookies-anime-defenders\n",
      "Failed to scrape content from https://www.sportskeeda.com/cricket/news-i-disagree-sunny-totally-aaron-finch-sunil-gavaskar-s-team-india-captaincy-remarks-2024-25-bgt: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/cricket/news-i-disagree-sunny-totally-aaron-finch-sunil-gavaskar-s-team-india-captaincy-remarks-2024-25-bgt\n",
      "Failed to scrape content from https://www.sportskeeda.com/basketball/news-why-joel-embiid-playing-tonight-la-clippers-exploring-76ers-superstar-s-status-nov-6: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/basketball/news-why-joel-embiid-playing-tonight-la-clippers-exploring-76ers-superstar-s-status-nov-6\n",
      "Failed to scrape content from https://www.sportskeeda.com/aew/news-swerve-strickland-shows-new-tattoo-bobby-lashley-s-beatdown-aew-dynamite-photo: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/aew/news-swerve-strickland-shows-new-tattoo-bobby-lashley-s-beatdown-aew-dynamite-photo\n",
      "Failed to scrape content from https://www.sportskeeda.com/roblox-news/how-get-bone-scythe-king-legacy: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/roblox-news/how-get-bone-scythe-king-legacy\n",
      "Failed to scrape content from https://www.sportskeeda.com/basketball/news-is-steph-curry-playing-tonight-boston-celtics-latest-2x-mvp-s-status-marquee-matchup-nov-6: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/basketball/news-is-steph-curry-playing-tonight-boston-celtics-latest-2x-mvp-s-status-marquee-matchup-nov-6\n",
      "Failed to scrape content from https://www.sportskeeda.com/us/reality-tv/pretty-cowardly-love-blind-argentina-star-agustina-criticizes-roberto-committing: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/us/reality-tv/pretty-cowardly-love-blind-argentina-star-agustina-criticizes-roberto-committing\n",
      "Failed to scrape content from https://www.sportskeeda.com/mma/news-coming-shock-world-british-slugger-jacob-smith-dedicates-world-title-challenge-rodtang-family-back-home: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/mma/news-coming-shock-world-british-slugger-jacob-smith-dedicates-world-title-challenge-rodtang-family-back-home\n",
      "Failed to scrape content from https://www.sportskeeda.com/us/music/news-what-sibo-selena-gomez-responds-alleged-body-shaming-comments-reveals-health-condition: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/us/music/news-what-sibo-selena-gomez-responds-alleged-body-shaming-comments-reveals-health-condition\n",
      "Failed to scrape content from https://www.sportskeeda.com/college-football/news-travis-hunter-gangs-shedeur-sanders-hilariously-troll-coach-prime-s-old-school-stuff-stealing-car: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/college-football/news-travis-hunter-gangs-shedeur-sanders-hilariously-troll-coach-prime-s-old-school-stuff-stealing-car\n",
      "Failed to scrape content from https://www.sportskeeda.com/cricket/news-i-inspired-watching-play-here-abhishek-sharma-revisits-memories-yuvraj-singh-s-six-sixes-durban-2007-t20-world-cup: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/cricket/news-i-inspired-watching-play-here-abhishek-sharma-revisits-memories-yuvraj-singh-s-six-sixes-durban-2007-t20-world-cup\n",
      "Failed to scrape content from https://www.sportskeeda.com/esports/espanyol-vs-valencia-which-better-team-ea-fc-25: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/esports/espanyol-vs-valencia-which-better-team-ea-fc-25\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-the-bloodline-saga-features-another-powerful-figure-besides-the-tribal-chief-according-wwe-legend: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-the-bloodline-saga-features-another-powerful-figure-besides-the-tribal-chief-according-wwe-legend\n",
      "Failed to scrape content from https://www.sportskeeda.com/us/k-pop/news-congratulations-jin-fans-react-bts-jin-s-pre-release-solo-track-i-ll-be-there-debuts-1-billboard-world-digital-song-sales-chart: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/us/k-pop/news-congratulations-jin-fans-react-bts-jin-s-pre-release-solo-track-i-ll-be-there-debuts-1-billboard-world-digital-song-sales-chart\n",
      "Failed to scrape content from https://www.sportskeeda.com/roblox-news/how-play-roblox-school-chromebook: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/roblox-news/how-play-roblox-school-chromebook\n",
      "Failed to scrape content from https://www.sportskeeda.com/us/movies/caddo-lake-soundtrack-the-definitive-guide-songs-movie: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/us/movies/caddo-lake-soundtrack-the-definitive-guide-songs-movie\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#add urls to this list to parse\n",
    "url_list = [\n",
    "        #MBFC High Credibility\n",
    "        \"https://www.espn.com/espn/rss/news\", #ESPN top headlines\n",
    "        \"https://deadspin.com/rss/\", #Deadspin \n",
    "        \"https://feeds.abcnews.com/abcnews/sportsheadlines\" #ABC news- espn sports\n",
    "        \"https://rss.nytimes.com/services/xml/rss/nyt/Sports.xml\", #NYT\n",
    "        \"https://www.nytimes.com/athletic/rss/news/\"#The Athletic- acquired by NYT\n",
    "        \"https://www.mlb.com/feeds/news/rss.xml\", #MLB news \n",
    "        \"https://www.reutersagency.com/feed/?best-topics=sports&post_type=best\", # Reuters\n",
    "        \"https://sports.yahoo.com/rss/\", #Yahoo News\n",
    "        \"https://www.cbssports.com/rss/headlines/\" #CBS sports general headlines \n",
    "\n",
    "        #MBFC questionable sources or medium credibility\n",
    "        \"https://notthebee.com/feed\", #not the bee\n",
    "        \"https://uproxx.com/sports/feed/\", #uproxx   \n",
    "        \"https://www.vibe.com/c/news/sports/feed/\", #The vibe - medium cred \n",
    "        \"https://moxie.foxnews.com/google-publisher/sports.xml\", #fox news \n",
    "        \"https://nypost.com/sports/feed/\" #NY post - medium cred\n",
    "\n",
    "        #NO MBFC RATING\n",
    "        \"https://www.sportscollectorsdaily.com/feed/\", #Sports Collectors Daily \n",
    "        \"https://news.sportslogos.net/feed/\", #SportsLogos.Net\n",
    "        \"https://www.sportingnews.com/us/rss\", #sportingnews.com\n",
    "        \"https://www.sportskeeda.com/feed\",#sportskeeda.com\n",
    "        \"https://sportsweez.com/feed/\", #sportsweez\n",
    "        \"https://sportsbrackets.net/feed/\", #sportsbracket\n",
    "        \"https://21sports.com/feed/\", # 21 sports\n",
    "        \"https://www.essentiallysports.com/feed/\", #essentiallysports\n",
    "        \"https://boxingnewsonline.net/feed/\", #boxing news\n",
    "        \"https://www.thecoldwire.com/feed/\", #the cold wire\n",
    "        \"https://sportsdark.com/feed/\", #sports dark\n",
    "]\n",
    "    \n",
    "entries = [] #list of dictionaries\n",
    "\n",
    "#--------------DEFINE FUNCTION TO SCRAPE-------------------\n",
    "def scrape_article_content(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        #extract content from common tags\n",
    "        article_body = (\n",
    "            soup.find(\"article\") or\n",
    "            soup.find(\"div\", {\"class\": \"post-content\"}) or\n",
    "            soup.find(\"div\", class_=\"article-body\") or\n",
    "            soup.find(\"div\", class_=\"article-content\") or\n",
    "            soup.find(\"section\", class_=\"article-section\") or\n",
    "            soup.find(\"div\", class_=\"main-content\") or\n",
    "            soup.find(\"div\", class_=\"content-body\")\n",
    "        )\n",
    "        \n",
    "        if article_body:\n",
    "            paragraphs = article_body.find_all(\"p\")\n",
    "        else:\n",
    "            paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "        #join all paragraphs into a single string\n",
    "        article_content = \" \".join(p.get_text() for p in paragraphs)\n",
    "        return article_content.strip() if article_content else \"No content found\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape content from {url}: {e}\")\n",
    "        return \"Failed to fetch content\"\n",
    "\n",
    "\n",
    "#run the function to collect feeds and scrape\n",
    "for url in url_list:\n",
    "    feed = feedparser.parse(url)\n",
    "    #feed_title= feed.feed.title\n",
    "    feed_title = getattr(feed.feed, \"title\", None)\n",
    "\n",
    "    \n",
    "    for entry in feed.entries:\n",
    "        entry_title = getattr(entry, \"title\", None)\n",
    "        entry_link = getattr(entry, \"link\", None)\n",
    "        entry_published_date = getattr(entry, \"published\", None)\n",
    "        entry_summary = getattr(entry, \"summary\", None)\n",
    "        entry_content = scrape_article_content(entry_link) #scrape\n",
    "        \n",
    "        entries.append({\n",
    "            \"feed_title\": feed_title,\n",
    "            \"entry_title\": entry_title,\n",
    "            \"entry_link\": entry_link,\n",
    "            \"entry_published_date\": entry_published_date,\n",
    "            \"entry_summary\": entry_summary,\n",
    "            \"entry_content\": entry_content,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(entries)\n",
    "#print(df)\n",
    "\n",
    "df.to_csv('RSS_sports_feeds_11-16.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b17ce3-4167-4ee2-b75b-0e30f8d21697",
   "metadata": {},
   "source": [
    "### Attempt to Scrape Links without RSS Feeds- not very effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9a3d96-4201-4150-8ecb-b14e133f886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# uncredible_urls = [\n",
    "#     \"https://www.tellerreport.com/sports\",\n",
    "#     \"https://www.newsbreak.com/mountain-view-ca-sports\",\n",
    "#     \"https://newsrnd.com/sports\",\n",
    "#     \"https://baltimorecitywire.com/stories/tag/53-sports\"\n",
    "# ]\n",
    "\n",
    "# # Function to scrape article details\n",
    "# def scrape_article(url):\n",
    "#     try:\n",
    "#         response = requests.get(url, timeout=10)\n",
    "#         response.raise_for_status()\n",
    "#         soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#         # Extract the article title\n",
    "#         title = soup.find(\"h1\").get_text() if soup.find(\"h1\") else soup.title.get_text()\n",
    "\n",
    "#         # Extract the publication date (common in <time> or meta tags)\n",
    "#         date = soup.find(\"time\")\n",
    "#         if date:\n",
    "#             publication_date = date.get(\"datetime\") or date.get_text()\n",
    "#         else:\n",
    "#             date_meta = soup.find(\"meta\", {\"name\": \"article:published_time\"})\n",
    "#             publication_date = date_meta[\"content\"] if date_meta else \"No date found\"\n",
    "\n",
    "#         # Extract the article content\n",
    "#         content_container = (\n",
    "#             soup.find(\"article\") or\n",
    "#             soup.find(\"div\", class_=[\"post-content\", \"article-body\", \"article-content\", \"content-body\"])\n",
    "#         )\n",
    "#         if content_container:\n",
    "#             paragraphs = content_container.find_all(\"p\")\n",
    "#         else:\n",
    "#             paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "#         content = \"\\n\".join(p.get_text() for p in paragraphs)\n",
    "\n",
    "#         return {\n",
    "#             \"Title\": title.strip(),\n",
    "#             \"Publication Date\": publication_date.strip(),\n",
    "#             \"Content\": content.strip()[:500] + \"...\",\n",
    "#             \"Link\": url\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to scrape {url}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# articles = []\n",
    "# for url in uncredible_urls:\n",
    "#     print(f\"Scraping: {url}\")\n",
    "#     article_details = scrape_article(url)\n",
    "#     if article_details:\n",
    "#         articles.append(article_details)\n",
    "\n",
    "# for article in articles:\n",
    "#     print(\"\\n--- Article ---\")\n",
    "#     print(f\"Title: {article['Title']}\")\n",
    "#     print(f\"Date: {article['Publication Date']}\")\n",
    "#     print(f\"Content Preview: {article['Content']}\")\n",
    "#     print(f\"Link: {article['Link']}\\n\")\n",
    "\n",
    "# df = pd.DataFrame(articles)\n",
    "# output_file = \"scraped_uncredible_articles.csv\"\n",
    "# df.to_csv(output_file, index=False)\n",
    "# print(f\"\\nResults saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f53448-164e-46d8-a16d-02c3dbaa7d0c",
   "metadata": {},
   "source": [
    "### Format DF to match DB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b6b1163a-ce9f-47f0-9c15-d7e5cceaf6e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tizia\\Anaconda4\\Lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "df['publication_date'] = df['entry_published_date'].apply(lambda x: parser.parse(x).date()) #parse different date formats to date object format\n",
    "dbdf = pd.read_csv('RSS_sports_feeds.csv')\n",
    "dbdf['team_or_player'] = df['entry_title']\n",
    "dbdf['source'] = df['feed_title']\n",
    "dbdf['publication_date'] = df['publication_date'] \n",
    "dbdf['content'] = df['entry_summary']\n",
    "dbdf['trust_score'] = 0.00  #default\n",
    "dbdf['classification'] = 'unknown' #default\n",
    "dbdf['link'] = df['entry_link']\n",
    "\n",
    "#make a new df in the format of the DB table for easy inserting\n",
    "sports_DB_df = dbdf[['team_or_player', 'source', 'publication_date', 'content', 'trust_score', 'classification', 'link']]\n",
    "#save to a new CSV \n",
    "sports_DB_df.to_csv('formatted_sports_posts_for_DB.csv', index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e65e92b-0473-40ed-9279-7d6f643fe6f4",
   "metadata": {},
   "source": [
    "### Examine 2 Lists of True and False Headlines to Discover Features for Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60f4d51a-90aa-4cf2-8699-ad47dcbd5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Lists\n",
    "false_headlines=[\n",
    "    \"BREAKING: Fox Sports Cancels ALL NFL Broadcasts \\\"Until Players Respect The Flag\\\"\",\n",
    "    \"Rugby Safer Than American Football \\\"For Health Reasons\\\": Biden\",\n",
    "    \"First woman to medal in six straight Olympics. Media and sponsors ignore her because she is outspoken pro-2A.\",\n",
    "    \"Novak Djokovic becomes the first professional athlete in history to be banned from a major sporting competition for not taking drugs\",\n",
    "    \"BREAKING: ESPN has fired Shannon Sharpe, per @ESPNNBA\",\n",
    "    \"The Minnesota Vikings have denounced Tim Walz: \\\"We don’t suppᴏrt his values.\\\"\",\n",
    "    \"'BREAKING: WNBA referees disqualify two players under league’s new \\\"no anthem kneeling\\\" rule\",\n",
    "    \"Nike announces termination of contract with Brittney Griner after \\\"strong backlash\\\" from online community: \\\"We need more athletes like Riley Gaines and less woke Brittney Griner!\\\"\",\n",
    "    \"KNEELING: After the University of Texas, all students who knelt during the national anthem were rounded up and REMOVED FROM SCHOLARSHIPS\",\n",
    "    \"Travis Kelce kneels during national anthem fined $10 million and thrown out of the game.\",\n",
    "    \"The NFL will now use facial recognition at every stadium to verify the identity of everyone at the game.\",\n",
    "    \"Mike Tyson says he’s willing to box Olympic DUDE with all proceeds to go to a battered women’s charity.\",\n",
    "    \"After winning silver, Yusef stood emotionless on the Olympic podium and declared, \\\"Sharon, if you’re watching this, I want my dog back.\\\"\",\n",
    "    \"Miami Dolphins QB Tua Tagovailoa will be sitting front row tonight in Doral for the Trump speech\",\n",
    "    \"BREAKING: The WNBA organizers have officially announced an investigation into the referees in all of Caitlin Clark's games for ignoring all dirty actions by her opponents against her\",\n",
    "    \"Chiefs' Coach Andy Reid \\\"fires 3 top players for anthem kneeling.\\\"\",\n",
    "    \"BREAKING: Caitlin Clark Rejects $400 Million Deal From Nike, \\\"Not With That Kaepernick Clown,\\\"\",\n",
    "    \"At Euro 2020, UEFA (European Football Association) ordered all team captains to wear \\\"OneLove\\\" bands. The band was used as a symbol of LGBTQ. But, Portugal captain Cristiano Ronaldo was the only European captain who did not wear the band.\",\n",
    "    \"Golden State Warriors refuse to visit White House after winning NBA title: reports\",\n",
    "    \"Taylor Swift faces a 10-game NFL ban following controversial political involvement - fans in uproar!\"\n",
    "]\n",
    "true_headlines=[\n",
    "    \"Did that really happen? Barbados v Grenada and a deliberate own goal\",\n",
    "    \"Breakdancing Will Not Be Busting A Move In 2028 Olympics\",\n",
    "    \"Breaking Will Not Be in The 2028 Los Angeles Olympics—What’s Next?\",\n",
    "    \"Braves Superstar Sets Atlanta-Era Record in 1st Inning\",\n",
    "    \"Only 20 schools in the Football Bowl Subdivision have athletic departments with revenue exceeding expenses\",\n",
    "    \"LATEST: Mitchell Stadium named America’s Best High School Football Stadium\",\n",
    "    \"Homes of Patrick Mahomes, Travis Kelce burglarized last month\",\n",
    "    \"Gregg Popovich recovering from mild stroke, no timeline for return set\",\n",
    "    \"Patrick Queen: I wasn’t wanted back with Ravens, it was definitely kind of upsetting\",\n",
    "    \"Odell Beckham Jr. boasts about taking 2021 Rams salary in Bitcoin National Football League Odell Beckham Jr. boasts about taking 2021 Rams salary in Bitcoin\",\n",
    "    \"Ecuador international soccer player Marco Angulo dies aged 22 following car crash\",\n",
    "    \"Shohei Ohtani Baseball Worth $4 Million Lands in Globally-Recognized Skyscraper\",\n",
    "    \"Kobe Bryant is the only person to have won both an Olympic medal and an Oscar\",\n",
    "    \"Bucks fan predicted Milwaukee-Phoenix NBA Finals all the way back in 2016\",\n",
    "    \"Chiefs kicker Butker congratulates women graduates and says most are more excited about motherhood\",\n",
    "    \"Kansas City Chiefs player faces backlash for graduation speech criticizing working women, calling Pride a \\\"deadly sin\\\"\", \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d48e1a6-9c29-4a2b-a38a-d0f53e5ed469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textstat\n",
    "from transformers import pipeline\n",
    "import string\n",
    "from textstat import flesch_reading_ease\n",
    "import re\n",
    "\n",
    "#functions for each feature we are considering\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def char_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def avg_word_length(text):\n",
    "    words = text.split()\n",
    "    return sum(len(word) for word in words) / len(words) if words else 0\n",
    "\n",
    "def all_capitalized_word_count(text):\n",
    "    return sum(1 for word in text.split() if word.isupper())\n",
    "\n",
    "def punctuation_count(text):\n",
    "    return sum(1 for char in text if char in string.punctuation)\n",
    "\n",
    "def exclamation_count(text):\n",
    "    return text.count(\"!\")\n",
    "\n",
    "def question_mark_count(text):\n",
    "    return text.count(\"?\")\n",
    "\n",
    "def readability_score(text): #high score = easier readability\n",
    "    return flesch_reading_ease(text)\n",
    "\n",
    "def smog_index(text): #readability based on the number of complex words (3+ syllables)\n",
    "    return textstat.smog_index(text)\n",
    "\n",
    "def count_quotation_pairs(text): \n",
    "    double_quotes = re.findall(r'\"[^\"]+\"', text) #Finds all sections of text in double quotes\n",
    "    return len(double_quotes)\n",
    "\n",
    "def variety_of_vocabularity(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words) / len(words) if words else 0\n",
    "\n",
    "\n",
    "sensational_words = [\"shocking\", \"amazing\", \"unbelievable\", \"you won’t believe\", \"incredible\", \"stunning\",\\\n",
    "                    \"astounding\", \"breathtaking\", \"outstanding\", \"thrilling\", \"must see\", \"terrible\", \"awful\",\\\n",
    "                     \"fantastic\", \"horrible\", \"remarkable\"]\n",
    "def count_sensational_words(text):\n",
    "    text = text.lower()\n",
    "    return sum(1 for word in sensational_words if word in text)\n",
    "\n",
    "\n",
    "absolute_words = [\"always\", \"never\", \"clearly\", \"obviously\", \"definitely\", \"everyone\", \"nobody\", \"all\",\\\n",
    "              \"none\", \"blatantly\", \"undoubtedly\", \"must\", \"should\"]\n",
    "def count_absolute_words(text):\n",
    "    words = text.lower().split()\n",
    "    return sum(1 for word in words if word in absolute_words)\n",
    "\n",
    "\n",
    "factuality_words = [\"proven\", \"irrefutable\", \"unarguable\", \"unquestionably\", \"certainly\", \"definitely\",\\\n",
    "                    \"undeniable\"]\n",
    "def count_factuality_words(text):\n",
    "    words = text.lower().split()\n",
    "    return sum(1 for word in words if word in factuality_words)\n",
    "\n",
    "\n",
    "subjective_words = [\"believe\", \"think\", \"feel\", \"prefer\", \"seems\", \"wish\"]\n",
    "def subjectivity_score(text):\n",
    "    words = text.lower().split()\n",
    "    subjective_count = sum(1 for word in words if word in subjective_words)\n",
    "    return subjective_count / len(words) if len(words) > 0 else 0\n",
    "\n",
    "objective_words = [\"reported\", \"measured\", \"confirmed\", \"analyzed\", \"observed\", \"recorded\",\\\n",
    "                   \"found\", \"documented\", \"verified\", \"tested\", \"studied\", \"calculated\", \"noted\",\\\n",
    "                   \"established\", \"evidence\", \"fact\", \"data\", \"statistics\", \"demonstrated\", \"shown\",\\\n",
    "                   \"results\", \"result\", \"evidence-based\", \"peer-reviewed\", \"sampled\", \"quantified\",\\\n",
    "                   \"evaluated\", \"experimented\", \"investigated\"]\n",
    "def objective_score(text):\n",
    "    words = text.lower().split()\n",
    "    objective_count = sum(1 for word in words if word in objective_words)\n",
    "    return objective_count / len(words) if len(words) > 0 else 0\n",
    "    \n",
    "\n",
    "pipe_finnews = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "def sentiment(text):\n",
    "    result = pipe_finnews(text)\n",
    "    return result[0][\"label\"] \n",
    "    \n",
    "    \n",
    "#add in source credibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321abb20-959e-47bc-a85e-169de141ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply these feature functions to the headlines to compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282d88e-3a8a-4283-af31-f011ec789135",
   "metadata": {},
   "source": [
    "### Define labeling heuristic and trust score to update sports_DB_df with ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb1d55-581f-44d7-9bed-4fbb1a8af079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
