{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "72517dfa-1720-49e6-b55a-f15cdf181498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/Combine_RSS_CSVs-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/SportsNewsTool-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/heuristic_analysis-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/All_RSS_articles.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/Combine_RSS_CSVs.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/SportsNewsTool.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/heuristic_analysis.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/.ipynb_checkpoints/labeled_RSS_posts-checkpoint.csv', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Sports_Misinformation_Tool/labeled_RSS_posts.csv', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 179edca] implemented source credibility, ran labeling, and outlined feature/glove calculation and model training setup\n",
      " 8 files changed, 11172 insertions(+), 273 deletions(-)\n",
      " create mode 100644 Sports_Misinformation_Tool/.ipynb_checkpoints/labeled_RSS_posts-checkpoint.csv\n",
      " create mode 100644 Sports_Misinformation_Tool/labeled_RSS_posts.csv\n",
      "Already up to date.\n",
      "branch 'main' set up to track 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:thernandez7/Sports_Misinformation_Tool.git\n",
      "   6f1abeb..179edca  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"implemented source credibility, ran labeling, and outlined feature/glove calculation and model training setup\"\n",
    "!git pull\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446acb8-a93e-418e-a0ec-3ef05f7389b8",
   "metadata": {},
   "source": [
    "## Sports Misinformation Classification Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc105918-5fb3-432a-b47f-f3717be38100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e525a-1cf9-47be-8298-238a25ce2667",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Connect to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fde6c4b-1920-4bb2-846f-61455f869aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully!\n"
     ]
    }
   ],
   "source": [
    "username = 'root'  \n",
    "password = 'password'\n",
    "host = 'localhost' \n",
    "database = 'sports_news_db'\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host=host,\n",
    "    user=username,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "if connection.is_connected():\n",
    "    print(\"Connected to the database successfully!\")\n",
    "\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{username}:{password}@{host}/{database}\", echo=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70ed146f-9fe7-4370-a3d2-898811f3e183",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Use this format to insert into the database\n",
    "\n",
    "INSERT INTO articles (team_or_player, source, publication_date, content, trust_score, classification, link)\n",
    "VALUES\n",
    "('New York Yankees, Los Angeles Lakers', 'ESPN', '2024-10-27', 'Yankees article content example.', 85.00, 'real', 'https://example.com/article1'),\n",
    "('Los Angeles Lakers', 'Twitter', '2024-10-27', 'Lakers article content example.', 60.00, 'fake', 'https://example.com/article2');\n",
    "\n",
    "\n",
    "#### Table fields \n",
    "Table Name: articles\n",
    "\n",
    "Fields: \n",
    "\n",
    "     id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "     \n",
    "     team_or_player VARCHAR(500), (This will be the article title that we can query- usually includes teams or names in it)\n",
    "     \n",
    "     source VARCHAR(200),\n",
    "     \n",
    "     publication_date DATE,\n",
    "     \n",
    "     content TEXT,\n",
    "     \n",
    "     trust_score DECIMAL(5, 2), \n",
    "     \n",
    "     classification ENUM('credible', 'uncredible', 'unknown') DEFAULT 'unknown',\n",
    "\n",
    "     link VARCHAR(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359168cc-f336-4972-b580-38575b45a13e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Simulate Tool Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9687e8d1-8c66-4df1-80cf-4bcf6f33805c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the team or player's name:  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No articles found for x.\n"
     ]
    }
   ],
   "source": [
    "team_or_player = input(\"Enter the team or player's name: \")\n",
    "\n",
    "query = f\"SELECT * FROM articles WHERE team_or_player LIKE '%{team_or_player}%'\" #search for entered name/team in the title \n",
    "df_result = pd.read_sql(query, con=engine, params={'team_or_player': team_or_player})\n",
    "\n",
    "#get results\n",
    "if not df_result.empty:\n",
    "    print(f\"Articles related to {team_or_player}:\")\n",
    "    display(df_result)\n",
    "else:\n",
    "    print(f\"No articles found for {team_or_player}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cee353-47af-48c3-a0eb-cf19ddcbc995",
   "metadata": {},
   "source": [
    "### Get Article Entries from RSS Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ea0136-a9b1-4fac-94f6-1949deec9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reddit API - collected 1876 posts\n",
    "# import csv\n",
    "# import praw\n",
    "# from datetime import datetime\n",
    "\n",
    "\n",
    "# reddit = praw.Reddit(\n",
    "#     client_id='w-kwRyPigyjYeG9DOiDc8g', \n",
    "#     client_secret='ZeDsvNH2YlpVH7F9wEWPkt5wkjLzqA',  \n",
    "#     user_agent='sports_misinfo_script'  \n",
    "# )\n",
    "\n",
    "# subreddit = reddit.subreddit('sports+fantasyfootball') #2 subreddits \n",
    "\n",
    "# recent_posts = []\n",
    "# for post in subreddit.new(limit= 5000):\n",
    "#     created_date = datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "#     recent_posts.append({\n",
    "#         'title': post.title,\n",
    "#         'score': post.score,\n",
    "#         'url': post.url,\n",
    "#         'id': post.id,\n",
    "#         'author': str(post.author),\n",
    "#         'text': post.selftext,\n",
    "#         'created_date': created_date,\n",
    "#         'num_comments': post.num_comments,\n",
    "#         'subreddit': post.subreddit.display_name,\n",
    "\n",
    "#     })\n",
    "\n",
    "# print(f\"Fetched {len(recent_posts)} posts\")\n",
    "\n",
    "# for i, post in enumerate(recent_posts[:5]):\n",
    "#     print(f\"{i+1}. Title: {post['title']} | Score: {post['score']} | URL: {post['url']}\")\n",
    "\n",
    "\n",
    "# #-------------------------------\n",
    "# #Save the data to a csv file\n",
    "# fieldnames = ['title', 'score', 'url', 'id', 'author', 'text', 'created_date', 'num_comments', 'subreddit']\n",
    "\n",
    "# with open('recent_sports_reddit_posts.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "#     writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "#     writer.writeheader()\n",
    "\n",
    "#     for post in recent_posts:\n",
    "#         writer.writerow(post)\n",
    "\n",
    "# print(\"Data successfully saved to 'recent_sports_reddit_posts.csv'\")\n",
    "# print(\"Data saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334d2970-7ee0-47e1-80d9-e01ae15fa4a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to scrape content from https://www.espn.com/nba/story/_/id/42468239/nba-power-rankings-okc-battles-west-magic-ascend-east: 403 Client Error: Forbidden for url: https://www.espn.com/nba/story/_/id/42468239/nba-power-rankings-okc-battles-west-magic-ascend-east\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42512141/braves-chris-sale-wins-national-league-cy-young-award: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42512141/braves-chris-sale-wins-national-league-cy-young-award\n",
      "Failed to scrape content from https://www.espn.com/wnba/story/_/id/42510300/caitlin-clark-play-unrivaled-league-source-says: 403 Client Error: Forbidden for url: https://www.espn.com/wnba/story/_/id/42510300/caitlin-clark-play-unrivaled-league-source-says\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42508628/sources-jets-owner-proposed-benching-aaron-rodgers-sept-30: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42508628/sources-jets-owner-proposed-benching-aaron-rodgers-sept-30\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42508409/man-pleads-guilty-2022-murders-three-virginia-players: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42508409/man-pleads-guilty-2022-murders-three-virginia-players\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42508209/yankees-wait-juan-soto-decision-good-meeting: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42508209/yankees-wait-juan-soto-decision-good-meeting\n",
      "Failed to scrape content from https://www.espn.com/nba/story/_/id/42511415/lakers-star-lebron-james-says-taking-social-media-break: 403 Client Error: Forbidden for url: https://www.espn.com/nba/story/_/id/42511415/lakers-star-lebron-james-says-taking-social-media-break\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42511309/new-giants-starter-tommy-devito-trying-avoid-fun-games: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42511309/new-giants-starter-tommy-devito-trying-avoid-fun-games\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42508014/sources-cubs-acquire-eli-morgan-trade-dfa-patrick-wisdom: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42508014/sources-cubs-acquire-eli-morgan-trade-dfa-patrick-wisdom\n",
      "Failed to scrape content from https://www.espn.com/womens-college-basketball/story/_/id/42497031/geno-auriemma-uconn-ncaa-coaching-record-most-wins-biggest-victories: 403 Client Error: Forbidden for url: https://www.espn.com/womens-college-basketball/story/_/id/42497031/geno-auriemma-uconn-ncaa-coaching-record-most-wins-biggest-victories\n",
      "Failed to scrape content from https://www.espn.com/mlb/story/_/id/42372887/2024-mlb-awards-mvp-cy-young-rookie-manager-year-predictions-results-analysis: 403 Client Error: Forbidden for url: https://www.espn.com/mlb/story/_/id/42372887/2024-mlb-awards-mvp-cy-young-rookie-manager-year-predictions-results-analysis\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42487935/curt-cignetti-google-indiana-hoosiers-college-football-playoff: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42487935/curt-cignetti-google-indiana-hoosiers-college-football-playoff\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42486681/nfl-mvp-watch-2024-top-candidates-odds-stats-lamar-jackson-josh-allen-jared-goff: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42486681/nfl-mvp-watch-2024-top-candidates-odds-stats-lamar-jackson-josh-allen-jared-goff\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42489596/how-trent-williams-trying-remain-nfl-best-offensive-tackle-36-years-old: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42489596/how-trent-williams-trying-remain-nfl-best-offensive-tackle-36-years-old\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42490559/college-football-playoff-anger-index-week-13-2024: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42490559/college-football-playoff-anger-index-week-13-2024\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42472542/college-football-2024-defense-stop-rate-week-13: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42472542/college-football-2024-defense-stop-rate-week-13\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42491569/college-football-bottom-10-week-12-louisville-failed-finish: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42491569/college-football-bottom-10-week-12-louisville-failed-finish\n",
      "Failed to scrape content from https://www.espn.com/nhl/story/_/id/42487524/nhl-2024-25-winnipeg-jets-surprise-standings-playoffs-stanley-cup-analytics: 403 Client Error: Forbidden for url: https://www.espn.com/nhl/story/_/id/42487524/nhl-2024-25-winnipeg-jets-surprise-standings-playoffs-stanley-cup-analytics\n",
      "Failed to scrape content from https://www.espn.com/nfl/story/_/id/42511163/nfl-packers-jordan-love-49ers-playoff-loss-rematch: 403 Client Error: Forbidden for url: https://www.espn.com/nfl/story/_/id/42511163/nfl-packers-jordan-love-49ers-playoff-loss-rematch\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42425837/predicting-ruben-amorims-first-11-games-manchester-united-manager: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42425837/predicting-ruben-amorims-first-11-games-manchester-united-manager\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42503749/uswnt-face-japan-colombia-australia-shebelieves-cup: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42503749/uswnt-face-japan-colombia-australia-shebelieves-cup\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42508357/paris-fc-billionaire-owners-klopp-help-transform-club: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42508357/paris-fc-billionaire-owners-klopp-help-transform-club\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42491931/juan-mata-buys-stake-san-diego-fc: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42491931/juan-mata-buys-stake-san-diego-fc\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42509544/alajuelense-threatens-legal-action-club-world-cup-spot: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42509544/alajuelense-threatens-legal-action-club-world-cup-spot\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42506764/fc-dallas-names-eric-quill-replace-interim-coach-luccin: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42506764/fc-dallas-names-eric-quill-replace-interim-coach-luccin\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42503887/tottenham-appeal-rodrigo-bentancurs-seven-game-fa-ban: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42503887/tottenham-appeal-rodrigo-bentancurs-seven-game-fa-ban\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42506067/uefa-award-romania-victory-kosovo-walk-off: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42506067/uefa-award-romania-victory-kosovo-walk-off\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42488870/inter-miami-coach-gerardo-martino-steps-personal-reasons: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42488870/inter-miami-coach-gerardo-martino-steps-personal-reasons\n",
      "Failed to scrape content from https://www.espn.com/womens-college-basketball/story/_/id/42489923/womens-college-basketball-power-rankings-2024-25-south-carolina-usc: 403 Client Error: Forbidden for url: https://www.espn.com/womens-college-basketball/story/_/id/42489923/womens-college-basketball-power-rankings-2024-25-south-carolina-usc\n",
      "Failed to scrape content from https://www.espn.com/wnba/story/_/id/42496717/wnba-coaching-changes-2025-los-angeles-sparks-hire-lynne-roberts: 403 Client Error: Forbidden for url: https://www.espn.com/wnba/story/_/id/42496717/wnba-coaching-changes-2025-los-angeles-sparks-hire-lynne-roberts\n",
      "Failed to scrape content from https://www.espn.com/wnba/story/_/id/42033470/wnba-coaching-changes-tracker-carousel-hires-2025-season: 403 Client Error: Forbidden for url: https://www.espn.com/wnba/story/_/id/42033470/wnba-coaching-changes-tracker-carousel-hires-2025-season\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42388502/big-questions-argentina-brazil-world-cup-qualifying: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42388502/big-questions-argentina-brazil-world-cup-qualifying\n",
      "Failed to scrape content from https://www.espn.com/boxing/story/_/id/42492823/jake-paul-receives-callouts-top-combat-sports-stars-defeating-mike-tyson: 403 Client Error: Forbidden for url: https://www.espn.com/boxing/story/_/id/42492823/jake-paul-receives-callouts-top-combat-sports-stars-defeating-mike-tyson\n",
      "Failed to scrape content from https://www.espn.com/mma/story/_/id/21807736/mma-divisional-rankings-ufc-bellator-pfl-rankings-weight-class: 403 Client Error: Forbidden for url: https://www.espn.com/mma/story/_/id/21807736/mma-divisional-rankings-ufc-bellator-pfl-rankings-weight-class\n",
      "Failed to scrape content from https://www.espn.com/tennis/story/_/id/42395852/rafael-nadal-retires-davis-cup-king-clay-greatest-tennis-players: 403 Client Error: Forbidden for url: https://www.espn.com/tennis/story/_/id/42395852/rafael-nadal-retires-davis-cup-king-clay-greatest-tennis-players\n",
      "Failed to scrape content from https://www.espn.com/fantasy/football/story/_/id/42505832/fantasy-football-week-12-start-sit-bench-trade: 403 Client Error: Forbidden for url: https://www.espn.com/fantasy/football/story/_/id/42505832/fantasy-football-week-12-start-sit-bench-trade\n",
      "Failed to scrape content from https://www.espn.com/nhl/story/_/id/42492979/chicago-blackhawks-st-louis-blues-2025-winter-classic-jerseys: 403 Client Error: Forbidden for url: https://www.espn.com/nhl/story/_/id/42492979/chicago-blackhawks-st-louis-blues-2025-winter-classic-jerseys\n",
      "Failed to scrape content from https://www.espn.com/college-football/story/_/id/42491149/usc-trojans-kobe-bryant-football-cleats-ucla-bruins: 403 Client Error: Forbidden for url: https://www.espn.com/college-football/story/_/id/42491149/usc-trojans-kobe-bryant-football-cleats-ucla-bruins\n",
      "Failed to scrape content from https://www.espn.com/soccer/story/_/id/42492191/soccer-transfer-rumors-news-man-united-move-branthwaite: 403 Client Error: Forbidden for url: https://www.espn.com/soccer/story/_/id/42492191/soccer-transfer-rumors-news-man-united-move-branthwaite\n",
      "Failed to scrape content from https://www.espn.com/golf/story/_/id/42485481/pga-tour-eligibility-reduced-field-size-reduced-tour-cards: 403 Client Error: Forbidden for url: https://www.espn.com/golf/story/_/id/42485481/pga-tour-eligibility-reduced-field-size-reduced-tour-cards\n",
      "Failed to scrape content from https://www.sportskeeda.com/anime/news-chainsaw-man-season-2-confirmed-shueisha-legal-filings: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/anime/news-chainsaw-man-season-2-confirmed-shueisha-legal-filings\n",
      "Failed to scrape content from https://www.sportskeeda.com/college-football/dj-lagway-injury-update-is-florida-qb-playing-today-lsu: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/college-football/dj-lagway-injury-update-is-florida-qb-playing-today-lsu\n",
      "Failed to scrape content from https://www.sportskeeda.com/college-football/news-colorado-vs-utah-box-score-stats-game-summary-ft-shedeur-sanders: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/college-football/news-colorado-vs-utah-box-score-stats-game-summary-ft-shedeur-sanders\n",
      "Failed to scrape content from https://www.sportskeeda.com/college-football/worse-58-year-old-mike-tyson-deion-sanders-colorado-fans-drag-utah-mud-ahead-week-12-clash: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/college-football/worse-58-year-old-mike-tyson-deion-sanders-colorado-fans-drag-utah-mud-ahead-week-12-clash\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/it-woke-little-anxious-when-dak-prescott-pissed-falling-nfl-draft: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/it-woke-little-anxious-when-dak-prescott-pissed-falling-nfl-draft\n",
      "Failed to scrape content from https://www.sportskeeda.com/college-football/news-texas-vs-arkansas-box-score-game-stats-summary-ft-quinn-ewers: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/college-football/news-texas-vs-arkansas-box-score-game-stats-summary-ft-quinn-ewers\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/news-ex-cowboys-star-pacman-jones-arrested-mike-tyson-jake-paul-s-fight-texas-report: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/news-ex-cowboys-star-pacman-jones-arrested-mike-tyson-jake-paul-s-fight-texas-report\n",
      "Failed to scrape content from https://www.sportskeeda.com/football/news-alan-shearer-refuses-pick-arsenal-manchester-city-star-names-premier-league-team-season-far: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/football/news-alan-shearer-refuses-pick-arsenal-manchester-city-star-names-premier-league-team-season-far\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-umaga-s-brother-addresses-possible-wwe-hall-fame-induction: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-umaga-s-brother-addresses-possible-wwe-hall-fame-induction\n",
      "Failed to scrape content from https://www.sportskeeda.com/football/news-obviously-france-can-succeed-without-mbappe-france-star-makes-confident-claim-ahead-clash-italy: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/football/news-obviously-france-can-succeed-without-mbappe-france-star-makes-confident-claim-ahead-clash-italy\n",
      "Failed to scrape content from https://www.sportskeeda.com/college-football/who-lee-corso-pick-today-week-12-espn-s-college-gameday-headgear-pick: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/college-football/who-lee-corso-pick-today-week-12-espn-s-college-gameday-headgear-pick\n",
      "Failed to scrape content from https://www.sportskeeda.com/nfl/is-dalton-kincaid-playing-sunday-latest-bills-te-week-11: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/nfl/is-dalton-kincaid-playing-sunday-latest-bills-te-week-11\n",
      "Failed to scrape content from https://www.sportskeeda.com/us/nhl/if-stays-healthy-hard-do-nhl-fans-left-debating-connor-mcdavid-joining-wayne-gretzky-another-historic-nhl-milestone-future: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/us/nhl/if-stays-healthy-hard-do-nhl-fans-left-debating-connor-mcdavid-joining-wayne-gretzky-another-historic-nhl-milestone-future\n",
      "Failed to scrape content from https://www.sportskeeda.com/football/luxembourg-vs-northern-ireland-prediction-betting-tips-november-18th-2024: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/football/luxembourg-vs-northern-ireland-prediction-betting-tips-november-18th-2024\n",
      "Failed to scrape content from https://www.sportskeeda.com/mma/news-prison-rules-mike-back-dillon-danis-reacts-mike-tyson-s-bare-rear-end-shot-getting-caught-camera-jake-paul-fight: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/mma/news-prison-rules-mike-back-dillon-danis-reacts-mike-tyson-s-bare-rear-end-shot-getting-caught-camera-jake-paul-fight\n",
      "Failed to scrape content from https://www.sportskeeda.com/football/news-if-saka-team-maybe-don-t-struggle-much-shaka-hislop-suggests-25-year-old-star-important-arsenal-bukayo-saka: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/football/news-if-saka-team-maybe-don-t-struggle-much-shaka-hislop-suggests-25-year-old-star-important-arsenal-bukayo-saka\n",
      "Failed to scrape content from https://www.sportskeeda.com/mma/news-photos-mvp-ring-girl-sydney-thomas-best-pictures-jake-paul-vs-mike-tyson-fight-week: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/mma/news-photos-mvp-ring-girl-sydney-thomas-best-pictures-jake-paul-vs-mike-tyson-fight-week\n",
      "Failed to scrape content from https://www.sportskeeda.com/football/news-why-everything-confidence-edwin-van-der-sar-shares-told-cristiano-ronaldo-training-manchester-united: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/football/news-why-everything-confidence-edwin-van-der-sar-shares-told-cristiano-ronaldo-training-manchester-united\n",
      "Failed to scrape content from https://www.sportskeeda.com/wwe/news-bronson-reed-sends-two-word-message-decimating-roman-reigns-aligning-solo-sikoa-wwe-smackdown: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/wwe/news-bronson-reed-sends-two-word-message-decimating-roman-reigns-aligning-solo-sikoa-wwe-smackdown\n",
      "Failed to scrape content from https://www.sportskeeda.com/us/nhl/chicago-blackhawks-vs-vancouver-canucks-game-preview-predictions-odds-november-16-2024: 403 Client Error: Forbidden for url: https://www.sportskeeda.com/us/nhl/chicago-blackhawks-vs-vancouver-canucks-game-preview-predictions-odds-november-16-2024\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#add urls to this list to parse\n",
    "url_list = [\n",
    "        # #MBFC High Credibility-9 \n",
    "        \"https://www.espn.com/espn/rss/news\", #ESPN top headlines\n",
    "        \"https://deadspin.com/rss/\", #Deadspin \n",
    "        \"https://feeds.abcnews.com/abcnews/sportsheadlines\", #ABC news- espn sports\n",
    "        \"https://rss.nytimes.com/services/xml/rss/nyt/Sports.xml\", #NYT\n",
    "        \"https://www.nytimes.com/athletic/rss/news/\", #The Athletic- acquired by NYT\n",
    "        \"https://www.mlb.com/feeds/news/rss.xml\", #MLB news \n",
    "        \"https://www.reutersagency.com/feed/?best-topics=sports&post_type=best\", # Reuters\n",
    "        \"https://sports.yahoo.com/rss/\", #Yahoo News\n",
    "        \"https://www.cbssports.com/rss/headlines/\", #CBS sports general headlines \n",
    "\n",
    "        #MBFC questionable sources or medium credibility- 5\n",
    "        \"https://notthebee.com/feed\", #not the bee\n",
    "        \"https://uproxx.com/sports/feed/\", #uproxx   \n",
    "        \"https://www.vibe.com/c/news/sports/feed/\", #The vibe - medium cred \n",
    "        \"https://moxie.foxnews.com/google-publisher/sports.xml\", #fox news \n",
    "        \"https://nypost.com/sports/feed/\", #NY post - medium cred\n",
    "\n",
    "        #NO MBFC RATING -11 \n",
    "        \"https://www.sportscollectorsdaily.com/feed/\", #Sports Collectors Daily \n",
    "        \"https://news.sportslogos.net/feed/\", #SportsLogos.Net\n",
    "        \"https://www.sportingnews.com/us/rss\", #sportingnews.com\n",
    "        \"https://www.sportskeeda.com/feed\",#sportskeeda.com\n",
    "        \"https://sportsweez.com/feed/\", #sportsweez\n",
    "        \"https://sportsbrackets.net/feed/\", #sportsbracket\n",
    "        \"https://21sports.com/feed/\", # 21 sports\n",
    "        \"https://www.essentiallysports.com/feed/\", #essentiallysports\n",
    "        \"https://boxingnewsonline.net/feed/\", #boxing news\n",
    "        \"https://www.thecoldwire.com/feed/\", #the cold wire\n",
    "        \"https://sportsdark.com/feed/\", #sports dark\n",
    "         \n",
    "]\n",
    "    \n",
    "entries = [] #list of dictionaries\n",
    "\n",
    "#--------------DEFINE FUNCTION TO SCRAPE-------------------\n",
    "def scrape_article_content(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        #extract content from common tags\n",
    "        article_body = (\n",
    "            soup.find(\"article\") or\n",
    "            soup.find(\"div\", {\"class\": \"post-content\"}) or\n",
    "            soup.find(\"div\", class_=\"article-body\") or\n",
    "            soup.find(\"div\", class_=\"article-content\") or\n",
    "            soup.find(\"section\", class_=\"article-section\") or\n",
    "            soup.find(\"div\", class_=\"main-content\") or\n",
    "            soup.find(\"div\", class_=\"content-body\")\n",
    "        )\n",
    "        \n",
    "        if article_body:\n",
    "            paragraphs = article_body.find_all(\"p\")\n",
    "        else:\n",
    "            paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "        #join all paragraphs into a single string\n",
    "        article_content = \" \".join(p.get_text() for p in paragraphs)\n",
    "        return article_content.strip() if article_content else \"No content found\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape content from {url}: {e}\")\n",
    "        return \"Failed to fetch content\"\n",
    "\n",
    "\n",
    "#run the function to collect feeds and scrape\n",
    "for url in url_list:\n",
    "    feed = feedparser.parse(url)\n",
    "    #feed_title= feed.feed.title\n",
    "    feed_title = getattr(feed.feed, \"title\", None)\n",
    "\n",
    "    \n",
    "    for entry in feed.entries:\n",
    "        entry_title = getattr(entry, \"title\", None)\n",
    "        entry_link = getattr(entry, \"link\", None)\n",
    "        entry_published_date = getattr(entry, \"published\", None)\n",
    "        entry_summary = getattr(entry, \"summary\", None)\n",
    "        entry_content = scrape_article_content(entry_link) #scrape\n",
    "        \n",
    "        entries.append({\n",
    "            \"feed_title\": feed_title,\n",
    "            \"entry_title\": entry_title,\n",
    "            \"entry_link\": entry_link,\n",
    "            \"entry_published_date\": entry_published_date,\n",
    "            \"entry_summary\": entry_summary,\n",
    "            \"entry_content\": entry_content,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(entries)\n",
    "#print(df)\n",
    "\n",
    "df.to_csv('RSS_sports_feeds_11-20.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b17ce3-4167-4ee2-b75b-0e30f8d21697",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attempt to Scrape Links without RSS Feeds- not very effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9a3d96-4201-4150-8ecb-b14e133f886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# uncredible_urls = [\n",
    "#     \"https://www.tellerreport.com/sports\",\n",
    "#     \"https://www.newsbreak.com/mountain-view-ca-sports\",\n",
    "#     \"https://newsrnd.com/sports\",\n",
    "#     \"https://baltimorecitywire.com/stories/tag/53-sports\"\n",
    "# ]\n",
    "\n",
    "# # Function to scrape article details\n",
    "# def scrape_article(url):\n",
    "#     try:\n",
    "#         response = requests.get(url, timeout=10)\n",
    "#         response.raise_for_status()\n",
    "#         soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#         # Extract the article title\n",
    "#         title = soup.find(\"h1\").get_text() if soup.find(\"h1\") else soup.title.get_text()\n",
    "\n",
    "#         # Extract the publication date (common in <time> or meta tags)\n",
    "#         date = soup.find(\"time\")\n",
    "#         if date:\n",
    "#             publication_date = date.get(\"datetime\") or date.get_text()\n",
    "#         else:\n",
    "#             date_meta = soup.find(\"meta\", {\"name\": \"article:published_time\"})\n",
    "#             publication_date = date_meta[\"content\"] if date_meta else \"No date found\"\n",
    "\n",
    "#         # Extract the article content\n",
    "#         content_container = (\n",
    "#             soup.find(\"article\") or\n",
    "#             soup.find(\"div\", class_=[\"post-content\", \"article-body\", \"article-content\", \"content-body\"])\n",
    "#         )\n",
    "#         if content_container:\n",
    "#             paragraphs = content_container.find_all(\"p\")\n",
    "#         else:\n",
    "#             paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "#         content = \"\\n\".join(p.get_text() for p in paragraphs)\n",
    "\n",
    "#         return {\n",
    "#             \"Title\": title.strip(),\n",
    "#             \"Publication Date\": publication_date.strip(),\n",
    "#             \"Content\": content.strip()[:500] + \"...\",\n",
    "#             \"Link\": url\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to scrape {url}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# articles = []\n",
    "# for url in uncredible_urls:\n",
    "#     print(f\"Scraping: {url}\")\n",
    "#     article_details = scrape_article(url)\n",
    "#     if article_details:\n",
    "#         articles.append(article_details)\n",
    "\n",
    "# for article in articles:\n",
    "#     print(\"\\n--- Article ---\")\n",
    "#     print(f\"Title: {article['Title']}\")\n",
    "#     print(f\"Date: {article['Publication Date']}\")\n",
    "#     print(f\"Content Preview: {article['Content']}\")\n",
    "#     print(f\"Link: {article['Link']}\\n\")\n",
    "\n",
    "# df = pd.DataFrame(articles)\n",
    "# output_file = \"scraped_uncredible_articles.csv\"\n",
    "# df.to_csv(output_file, index=False)\n",
    "# print(f\"\\nResults saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd4fae-b096-4e94-beed-e7c6b237031a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Format DF to match DB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b6b1163a-ce9f-47f0-9c15-d7e5cceaf6e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tizia\\Anaconda4\\Lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "df['publication_date'] = df['entry_published_date'].apply(lambda x: parser.parse(x).date()) #parse different date formats to date object format\n",
    "dbdf = pd.read_csv('RSS_sports_feeds.csv')\n",
    "dbdf['team_or_player'] = df['entry_title']\n",
    "dbdf['source'] = df['feed_title']\n",
    "dbdf['publication_date'] = df['publication_date'] \n",
    "dbdf['content'] = df['entry_summary']    #entry content if not empty? or keep as summary\n",
    "dbdf['trust_score'] = 0.00               #CHANGE to score column\n",
    "dbdf['classification'] = 'unknown'       #CHANGE to label column \n",
    "dbdf['link'] = df['entry_link']\n",
    "\n",
    "#make a new df in the format of the DB table for easy inserting\n",
    "sports_DB_df = dbdf[['team_or_player', 'source', 'publication_date', 'content', 'trust_score', 'classification', 'link']]\n",
    "#save to a new CSV \n",
    "sports_DB_df.to_csv('formatted_sports_posts_for_DB.csv', index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59c465-65a2-414d-90d3-7cb99ffb36e9",
   "metadata": {},
   "source": [
    "### Feature Computation Functions - use some for labeling and others for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbc4a29c-616d-475e-bad1-56ae7771036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\tizia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# !pip install textstat\n",
    "from transformers import pipeline\n",
    "import string\n",
    "from textstat import flesch_reading_ease\n",
    "import textstat\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "#functions for each feature we are considering\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def char_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def avg_word_length(text):\n",
    "    words = text.split()\n",
    "    return sum(len(word) for word in words) / len(words) if words else 0\n",
    "\n",
    "def all_capitalized_word_count(text):\n",
    "    return sum(1 for word in text.split() if word.isupper())\n",
    "\n",
    "def punctuation_count(text):\n",
    "    return sum(1 for char in text if char in string.punctuation)\n",
    "\n",
    "def exclamation_count(text):\n",
    "    return text.count(\"!\")\n",
    "\n",
    "def question_mark_count(text):\n",
    "    return text.count(\"?\")\n",
    "\n",
    "def readability_score(text): #high score = easier readability\n",
    "    return flesch_reading_ease(text)\n",
    "\n",
    "def smog_index(text): #readability based on the number of complex words (3+ syllables)\n",
    "    return textstat.smog_index(text)\n",
    "\n",
    "def count_quotation_pairs(text): \n",
    "    double_quotes = re.findall(r'\"[^\"]+\"', text) #Finds all sections of text in double quotes\n",
    "    return len(double_quotes)\n",
    "\n",
    "def variety_of_vocabularity(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words) / len(words) if words else 0\n",
    "\n",
    "\n",
    "sensational_words = [\"shocking\",\"shock\", \"amazing\", \"unbelievable\", \"you won’t believe\", \"incredible\", \"stunning\",\\\n",
    "                    \"astounding\", \"breathtaking\", \"outstanding\", \"thrilling\", \"must see\", \"terrible\", \"awful\",\\\n",
    "                     \"fantastic\", \"horrible\", \"remarkable\"]\n",
    "def count_sensational_words(text):\n",
    "    text = text.lower()\n",
    "    return sum(1 for word in sensational_words if word in text)\n",
    "\n",
    "\n",
    "absolute_words = [\"always\", \"never\", \"clearly\", \"obviously\", \"definitely\", \"everyone\", \"nobody\", \"all\",\\\n",
    "              \"none\", \"blatantly\", \"undoubtedly\", \"must\", \"should\"]\n",
    "def count_absolute_words(text):\n",
    "    words = text.lower().split()\n",
    "    return sum(1 for word in words if word in absolute_words)\n",
    "\n",
    "\n",
    "factuality_words = [\"proven\", \"irrefutable\", \"unarguable\", \"unquestionably\", \"certainly\", \"definitely\",\\\n",
    "                    \"undeniable\"]\n",
    "def count_factuality_words(text):\n",
    "    words = text.lower().split()\n",
    "    return sum(1 for word in words if word in factuality_words)\n",
    "\n",
    "\n",
    "subjective_words = [\"believe\", \"think\", \"feel\", \"prefer\", \"seems\", \"wish\"]\n",
    "def subjectivity_score(text):\n",
    "    words = text.lower().split()\n",
    "    subjective_count = sum(1 for word in words if word in subjective_words)\n",
    "    return subjective_count / len(words) if len(words) > 0 else 0\n",
    "\n",
    "objective_words = [\"reported\", \"measured\", \"confirmed\", \"analyzed\", \"observed\", \"recorded\",\\\n",
    "                   \"found\", \"documented\", \"verified\", \"tested\", \"studied\", \"calculated\", \"noted\",\\\n",
    "                   \"established\", \"evidence\", \"fact\", \"data\", \"statistics\", \"demonstrated\", \"shown\",\\\n",
    "                   \"results\", \"result\", \"evidence-based\", \"peer-reviewed\", \"sampled\", \"quantified\",\\\n",
    "                   \"evaluated\", \"experimented\", \"investigated\"]\n",
    "def objective_score(text):\n",
    "    words = text.lower().split()\n",
    "    objective_count = sum(1 for word in words if word in objective_words)\n",
    "    return objective_count / len(words) if len(words) > 0 else 0\n",
    "\n",
    "\n",
    "def count_numerics(text):\n",
    "    numerical_count = len(re.findall(r'\\d+', text)) \n",
    "    return numerical_count\n",
    "\n",
    "\n",
    "pipe_finnews = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "def sentiment(text):\n",
    "    result = pipe_finnews(text)\n",
    "    return result[0][\"label\"] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282d88e-3a8a-4283-af31-f011ec789135",
   "metadata": {},
   "source": [
    "### Define Labeling Heuristic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f055a2fa-dd0d-4480-88ff-0744cbe40bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_credibility_score(headline, source_credibility):\n",
    "    # Source credibility weights\n",
    "    SOURCE_CREDIBILITY = {\n",
    "        'high': 1.0,\n",
    "        'unknown': 0,\n",
    "        'medium': -0.5,\n",
    "        'low': -1.0\n",
    "    }\n",
    "    \n",
    "    # Top heuristics and their weights (based on the difference column)\n",
    "    heuristics = {\n",
    "        'smog_index': {\n",
    "            'weight': 9.448,  # From the Difference column\n",
    "            'true_avg': 0.124, # From the True_Avg column\n",
    "            'false_avg': 1.169 # From the False_Avg column\n",
    "        },\n",
    "        'factuality_words_count': {\n",
    "            'weight': 8.200,  \n",
    "            'true_avg': 0.000263,\n",
    "            'false_avg': 0.002158\n",
    "        },\n",
    "        'exclamation_count': {\n",
    "            'weight': 6.326, \n",
    "            'true_avg': 0.0192,\n",
    "            'false_avg': 0.1215\n",
    "        },\n",
    "        'subjectivity_score': {\n",
    "            'weight': 4.308,  \n",
    "            'true_avg': 0.000373,\n",
    "            'false_avg': 0.001606\n",
    "        },\n",
    "        'question_mark_count': {\n",
    "            'weight': 4.285,  \n",
    "            'true_avg': 0.0327,\n",
    "            'false_avg': 0.1403\n",
    "        },\n",
    "        'count_numerics': {\n",
    "            'weight': 3.089,  \n",
    "            'true_avg': 0.7496,\n",
    "            'false_avg': 0.2427\n",
    "        }\n",
    "    }   \n",
    "    \n",
    "    # Calculate metrics for each of the heuristics we're using\n",
    "    metrics = {\n",
    "        'smog_index': smog_index(headline),\n",
    "        'factuality_words_count': count_factuality_words(headline),\n",
    "        'exclamation_count': exclamation_count(headline),\n",
    "        'subjectivity_score': subjectivity_score(headline),\n",
    "        'question_mark_count': question_mark_count(headline),\n",
    "        'count_numerics': count_numerics(headline)\n",
    "    }\n",
    "\n",
    "    # Initialize the credibility score\n",
    "    credibility_score = 0\n",
    "    \n",
    "    # Calculate scores for each heuristic\n",
    "    for metric, values in heuristics.items():\n",
    "        true_avg = values['true_avg']\n",
    "        false_avg = values['false_avg']\n",
    "        weight = values['weight']\n",
    "        current_value = metrics[metric]\n",
    "        \n",
    "        # Calculate which average the current value is closer to\n",
    "        dist_to_true = abs(current_value - true_avg)\n",
    "        dist_to_false = abs(current_value - false_avg)\n",
    "        \n",
    "        # Calculate percentage difference from the midpoint\n",
    "        midpoint = (true_avg + false_avg) / 2            \n",
    "        percent_diff = abs(current_value - midpoint) / midpoint\n",
    "        \n",
    "        # Add or subtract from score based on which average it's closer to\n",
    "        if dist_to_true < dist_to_false:\n",
    "            credibility_score += weight * percent_diff\n",
    "        else:\n",
    "            credibility_score -= weight * percent_diff\n",
    "        \n",
    "        # print(f\"{metric}: {current_value:.4f}\\n\\tWeight: {weight:.2f}\\n\\tPercent Difference: {percent_diff:.4f}\\n\\tCredibility Score: {credibility_score:.2f}\")\n",
    "    \n",
    "    # Add source credibility modifier\n",
    "    if source_credibility: \n",
    "        source_credibility_score = SOURCE_CREDIBILITY.get(source_credibility.lower(), SOURCE_CREDIBILITY['unknown'])\n",
    "        weight = 10\n",
    "        credibility_score += (source_credibility_score * weight)\n",
    "        # print(f\"source_credibility: {source_credibility_score:.2f}\\n\\tWeight: {weight:.2f}\\n\\tCredibility Score: {credibility_score:.2f}\")\n",
    "\n",
    "    return credibility_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d0293-0598-4772-9e11-a55b7592cd38",
   "metadata": {},
   "source": [
    "### Define Source credibilty of each source and run Labeling Heuristic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e839780d-0227-4742-9909-246246e03b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NY Post Sports – Latest News, Scores, Stats & Videos' 'ABC News: Sports'\n",
      " 'Latest Headlines - The Athletic' 'www.espn.com - TOP'\n",
      " 'Deadspin > Sports News Without Fear, Favor or Compromise'\n",
      " 'Yahoo! Sports - News, Scores, Standings, Rumors, Fantasy Games'\n",
      " 'Sports – UPROXX' 'Sports' 'Latest Sports News Today on Fox News'\n",
      " 'SportsLogos.Net News' 'Sporting News RSS' 'Sports Weez'\n",
      " 'Sports Brackets' '21Sports.com' 'Boxing News' 'The Cold Wire'\n",
      " 'Sportsdark' 'EssentiallySports' 'Sportskeeda' 'MLB News' 'Not the Bee'\n",
      " 'FOX Sports Digital' 'Sports Collectors Daily']\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "#------------------------Determine source credibility-------------------------------------------\n",
    "\n",
    "all_articles_df = pd.read_csv('All_RSS_articles.csv')\n",
    "print(all_articles_df[\"feed_title\"].unique())\n",
    "    \n",
    "high_cred= [\n",
    "    'www.espn.com - TOP',\n",
    "    'Deadspin > Sports News Without Fear, Favor or Compromise',\n",
    "    'Yahoo! Sports - News, Scores, Standings, Rumors, Fantasy Games',\n",
    "    'MLB News',\n",
    "    'ABC News: Sports',\n",
    "    'Latest Headlines- The Athletic',\n",
    "    'NYT > Sports',\n",
    "    'CBSSports.com Headlines',\n",
    "]\n",
    "\n",
    "medium_cred=[\n",
    "    'Sports', #vibe\n",
    "    'NY Post Sports – Latest News, Scores, Stats & Videos' 'ABC News: Sports',\n",
    "]  \n",
    "\n",
    "low_cred=[\n",
    "    'Sports – UPROXX',\n",
    "    'Not the Bee',\n",
    "    'Latest Sports News Today on Fox News', #foxnews.com\n",
    "]\n",
    "\n",
    "no_cred=[\n",
    "    'SportsLogos.Net News',\n",
    "    'Sporting News RSS', \n",
    "    'Sports Weez', \n",
    "    'Sports Brackets',\n",
    "    '21Sports.com', \n",
    "    'Boxing News', \n",
    "    'The Cold Wire', \n",
    "    'Sportsdark',\n",
    "    'EssentiallySports', \n",
    "    'Sportskeeda', \n",
    "    'Sports Collectors Daily',\n",
    "    'FOX Sports Digital', #foxsports.com\n",
    "]\n",
    "\n",
    "def determine_source_credibility(feed_title):\n",
    "    if feed_title in high_cred:\n",
    "        return \"high\"\n",
    "    elif feed_title in medium_cred:\n",
    "        return \"medium\"\n",
    "    elif feed_title in low_cred:\n",
    "        return \"low\"\n",
    "    else:\n",
    "        return \"unknown\"  \n",
    "\n",
    "\n",
    "#Create a new column for source_credibility based on the feed_title\n",
    "all_articles_df[\"source_credibility\"] = all_articles_df[\"feed_title\"].apply(determine_source_credibility)\n",
    "\n",
    "\n",
    "CREDIBLE_VALUE= 30 ##PLACEHOLDER THRESHOLD NEEDED TO BE CREDIBLE ******************CHANGE*********\n",
    "credibility_scores = []\n",
    "credibility_labels = []\n",
    "for index, row in all_articles_df.iterrows():\n",
    "    #get the headline and source_credibility\n",
    "    headline = row[\"entry_title\"]\n",
    "    source_credibility = row[\"source_credibility\"]\n",
    "    \n",
    "    #Calculate the credibility score \n",
    "    score= calculate_credibility_score(headline, source_credibility)\n",
    "    credibility_scores.append(score) #add to list\n",
    "\n",
    "    if score>= CREDIBLE_VALUE:\n",
    "        credibility_labels.append(\"credible\")\n",
    "    else:\n",
    "        credibility_labels.append(\"uncredible\")\n",
    "\n",
    "\n",
    "all_articles_df[\"credibility_score\"] = credibility_scores\n",
    "all_articles_df[\"credibility_label\"] = credibility_labels\n",
    "\n",
    "all_articles_df.to_csv(\"labeled_RSS_posts.csv\")\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2587a256-ff31-4908-b906-54013a5b3f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feed_title</th>\n",
       "      <th>entry_title</th>\n",
       "      <th>entry_link</th>\n",
       "      <th>entry_published_date</th>\n",
       "      <th>entry_summary</th>\n",
       "      <th>entry_content</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>source_credibility</th>\n",
       "      <th>credibility_score</th>\n",
       "      <th>credibility_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NY Post Sports – Latest News, Scores, Stats &amp; ...</td>\n",
       "      <td>Ohio State center suffers season-ending Achill...</td>\n",
       "      <td>https://nypost.com/2024/11/19/sports/ohio-stat...</td>\n",
       "      <td>Tue, 19 Nov 2024 23:21:07 -0500</td>\n",
       "      <td>McLaughlin had been Ohio State’s starting cent...</td>\n",
       "      <td>Ohio State center Seth McLaughlin suffered a t...</td>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>unknown</td>\n",
       "      <td>29.478000</td>\n",
       "      <td>uncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY Post Sports – Latest News, Scores, Stats &amp; ...</td>\n",
       "      <td>Guardians’ Stephen Vogt and Brewers’ Pat Murph...</td>\n",
       "      <td>https://nypost.com/2024/11/19/sports/indians-s...</td>\n",
       "      <td>Tue, 19 Nov 2024 22:46:09 -0500</td>\n",
       "      <td>Pat Murphy won NL Manager of the Year on Tuesd...</td>\n",
       "      <td>Milwaukee’s Pat Murphy and Cleveland’s Stephen...</td>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>unknown</td>\n",
       "      <td>29.478000</td>\n",
       "      <td>uncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NY Post Sports – Latest News, Scores, Stats &amp; ...</td>\n",
       "      <td>Cam Johnson goes off for 34 points as shorthan...</td>\n",
       "      <td>https://nypost.com/2024/11/19/sports/cam-johns...</td>\n",
       "      <td>Tue, 19 Nov 2024 22:43:18 -0500</td>\n",
       "      <td>The Nets found a way to replicate Thomas’ prod...</td>\n",
       "      <td>The status of leading scorer Cam Thomas gradua...</td>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>unknown</td>\n",
       "      <td>35.703940</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY Post Sports – Latest News, Scores, Stats &amp; ...</td>\n",
       "      <td>The possible candidates to replace Joe Douglas...</td>\n",
       "      <td>https://nypost.com/2024/11/19/sports/the-early...</td>\n",
       "      <td>Tue, 19 Nov 2024 22:19:51 -0500</td>\n",
       "      <td>The Jets fired Joe Douglas on Tuesday and now ...</td>\n",
       "      <td>The Jets fired Joe Douglas on Tuesday and now ...</td>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>unknown</td>\n",
       "      <td>29.478000</td>\n",
       "      <td>uncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABC News: Sports</td>\n",
       "      <td>Mark Scheifele scores a hat trick and league-l...</td>\n",
       "      <td>https://abcnews.go.com/Sports/wireStory/mark-s...</td>\n",
       "      <td>Tue, 19 Nov 2024 23:54:18 -0500</td>\n",
       "      <td>Mark Scheifele had his ninth career hat trick,...</td>\n",
       "      <td>Mark Scheifele had his ninth career hat trick,...</td>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>high</td>\n",
       "      <td>51.929879</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>SportsLogos.Net News</td>\n",
       "      <td>NFL Week 9 Uniform Schedule: Giants, Eagles, P...</td>\n",
       "      <td>https://news.sportslogos.net/2024/11/03/nfl-we...</td>\n",
       "      <td>Sun, 03 Nov 2024 16:25:35 +0000</td>\n",
       "      <td>Our weekly series that looks at every uniform ...</td>\n",
       "      <td>The midway point of the 2024-25 season is here...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>35.703940</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>SportsLogos.Net News</td>\n",
       "      <td>QMJHL’s Quebec Remparts Pay Homage to Beloved ...</td>\n",
       "      <td>https://news.sportslogos.net/2024/11/02/qmjhls...</td>\n",
       "      <td>Sat, 02 Nov 2024 15:00:00 +0000</td>\n",
       "      <td>Jerseys worn Friday vs. Sherbrooke Phoenix ins...</td>\n",
       "      <td>The Quebec Remparts paid homage to one of thei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>29.478000</td>\n",
       "      <td>uncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>SportsLogos.Net News</td>\n",
       "      <td>Oregon Ducks Unveil Final “Generation O” Unifo...</td>\n",
       "      <td>https://news.sportslogos.net/2024/11/02/oregon...</td>\n",
       "      <td>Sat, 02 Nov 2024 05:03:33 +0000</td>\n",
       "      <td>Oregon unveiled the fifth and final combinatio...</td>\n",
       "      <td>The Oregon football program unveiled the fifth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>29.478000</td>\n",
       "      <td>uncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>SportsLogos.Net News</td>\n",
       "      <td>Illinois Fighting Illini Unveil Military Appre...</td>\n",
       "      <td>https://news.sportslogos.net/2024/11/02/illino...</td>\n",
       "      <td>Sat, 02 Nov 2024 04:02:08 +0000</td>\n",
       "      <td>Illinois will wear a special helmet design dur...</td>\n",
       "      <td>The Illinois football program will wear a spec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>29.478000</td>\n",
       "      <td>uncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>SportsLogos.Net News</td>\n",
       "      <td>Dodgers Set World Series Sales Records</td>\n",
       "      <td>https://news.sportslogos.net/2024/11/01/dodger...</td>\n",
       "      <td>Fri, 01 Nov 2024 19:22:21 +0000</td>\n",
       "      <td>The Los Angeles Dodgers set a series of mercha...</td>\n",
       "      <td>The Los Angeles Dodgers’ string of success did...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>29.478000</td>\n",
       "      <td>uncredible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2370 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feed_title  \\\n",
       "0     NY Post Sports – Latest News, Scores, Stats & ...   \n",
       "1     NY Post Sports – Latest News, Scores, Stats & ...   \n",
       "2     NY Post Sports – Latest News, Scores, Stats & ...   \n",
       "3     NY Post Sports – Latest News, Scores, Stats & ...   \n",
       "4                                      ABC News: Sports   \n",
       "...                                                 ...   \n",
       "2365                               SportsLogos.Net News   \n",
       "2366                               SportsLogos.Net News   \n",
       "2367                               SportsLogos.Net News   \n",
       "2368                               SportsLogos.Net News   \n",
       "2369                               SportsLogos.Net News   \n",
       "\n",
       "                                            entry_title  \\\n",
       "0     Ohio State center suffers season-ending Achill...   \n",
       "1     Guardians’ Stephen Vogt and Brewers’ Pat Murph...   \n",
       "2     Cam Johnson goes off for 34 points as shorthan...   \n",
       "3     The possible candidates to replace Joe Douglas...   \n",
       "4     Mark Scheifele scores a hat trick and league-l...   \n",
       "...                                                 ...   \n",
       "2365  NFL Week 9 Uniform Schedule: Giants, Eagles, P...   \n",
       "2366  QMJHL’s Quebec Remparts Pay Homage to Beloved ...   \n",
       "2367  Oregon Ducks Unveil Final “Generation O” Unifo...   \n",
       "2368  Illinois Fighting Illini Unveil Military Appre...   \n",
       "2369             Dodgers Set World Series Sales Records   \n",
       "\n",
       "                                             entry_link  \\\n",
       "0     https://nypost.com/2024/11/19/sports/ohio-stat...   \n",
       "1     https://nypost.com/2024/11/19/sports/indians-s...   \n",
       "2     https://nypost.com/2024/11/19/sports/cam-johns...   \n",
       "3     https://nypost.com/2024/11/19/sports/the-early...   \n",
       "4     https://abcnews.go.com/Sports/wireStory/mark-s...   \n",
       "...                                                 ...   \n",
       "2365  https://news.sportslogos.net/2024/11/03/nfl-we...   \n",
       "2366  https://news.sportslogos.net/2024/11/02/qmjhls...   \n",
       "2367  https://news.sportslogos.net/2024/11/02/oregon...   \n",
       "2368  https://news.sportslogos.net/2024/11/02/illino...   \n",
       "2369  https://news.sportslogos.net/2024/11/01/dodger...   \n",
       "\n",
       "                 entry_published_date  \\\n",
       "0     Tue, 19 Nov 2024 23:21:07 -0500   \n",
       "1     Tue, 19 Nov 2024 22:46:09 -0500   \n",
       "2     Tue, 19 Nov 2024 22:43:18 -0500   \n",
       "3     Tue, 19 Nov 2024 22:19:51 -0500   \n",
       "4     Tue, 19 Nov 2024 23:54:18 -0500   \n",
       "...                               ...   \n",
       "2365  Sun, 03 Nov 2024 16:25:35 +0000   \n",
       "2366  Sat, 02 Nov 2024 15:00:00 +0000   \n",
       "2367  Sat, 02 Nov 2024 05:03:33 +0000   \n",
       "2368  Sat, 02 Nov 2024 04:02:08 +0000   \n",
       "2369  Fri, 01 Nov 2024 19:22:21 +0000   \n",
       "\n",
       "                                          entry_summary  \\\n",
       "0     McLaughlin had been Ohio State’s starting cent...   \n",
       "1     Pat Murphy won NL Manager of the Year on Tuesd...   \n",
       "2     The Nets found a way to replicate Thomas’ prod...   \n",
       "3     The Jets fired Joe Douglas on Tuesday and now ...   \n",
       "4     Mark Scheifele had his ninth career hat trick,...   \n",
       "...                                                 ...   \n",
       "2365  Our weekly series that looks at every uniform ...   \n",
       "2366  Jerseys worn Friday vs. Sherbrooke Phoenix ins...   \n",
       "2367  Oregon unveiled the fifth and final combinatio...   \n",
       "2368  Illinois will wear a special helmet design dur...   \n",
       "2369  The Los Angeles Dodgers set a series of mercha...   \n",
       "\n",
       "                                          entry_content publication_date  \\\n",
       "0     Ohio State center Seth McLaughlin suffered a t...       2024-11-19   \n",
       "1     Milwaukee’s Pat Murphy and Cleveland’s Stephen...       2024-11-19   \n",
       "2     The status of leading scorer Cam Thomas gradua...       2024-11-19   \n",
       "3     The Jets fired Joe Douglas on Tuesday and now ...       2024-11-19   \n",
       "4     Mark Scheifele had his ninth career hat trick,...       2024-11-19   \n",
       "...                                                 ...              ...   \n",
       "2365  The midway point of the 2024-25 season is here...              NaN   \n",
       "2366  The Quebec Remparts paid homage to one of thei...              NaN   \n",
       "2367  The Oregon football program unveiled the fifth...              NaN   \n",
       "2368  The Illinois football program will wear a spec...              NaN   \n",
       "2369  The Los Angeles Dodgers’ string of success did...              NaN   \n",
       "\n",
       "     source_credibility  credibility_score credibility_label  \n",
       "0               unknown          29.478000        uncredible  \n",
       "1               unknown          29.478000        uncredible  \n",
       "2               unknown          35.703940          credible  \n",
       "3               unknown          29.478000        uncredible  \n",
       "4                  high          51.929879          credible  \n",
       "...                 ...                ...               ...  \n",
       "2365            unknown          35.703940          credible  \n",
       "2366            unknown          29.478000        uncredible  \n",
       "2367            unknown          29.478000        uncredible  \n",
       "2368            unknown          29.478000        uncredible  \n",
       "2369            unknown          29.478000        uncredible  \n",
       "\n",
       "[2370 rows x 10 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles_df #labeled dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d86b0-433e-4ac5-a6ab-d9387ac9e976",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "-get number of credible labels vs uncredible counts\n",
    "\n",
    "-number of each source (using feed title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8772958-80fe-4806-a4d4-1d1575f98e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbdf49-1311-4a40-b03b-68f34a343e6e",
   "metadata": {},
   "source": [
    "## Train a model using glove and additional features, source split to eval if model can generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd5c00-9607-4b3f-b239-f1bba8c07deb",
   "metadata": {},
   "source": [
    "### Turn each headline into a glove embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025818fa-d3b3-4ce6-b060-e3211657a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#article vec is mean of token's embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cceebc-80fb-44aa-8851-67736714e38a",
   "metadata": {},
   "source": [
    "### Prep the data into train and test by source split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f301db0a-a60e-4e25-9183-2350b07f4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(headline): #features not in heuristic for labels \n",
    "    return np.array([\n",
    "        word_count(headline),\n",
    "        char_count(headline),\n",
    "        avg_word_length(headline),\n",
    "        all_capitalized_word_count(headline),\n",
    "        punctuation_count(headline),\n",
    "        readability_score(headline),\n",
    "        count_quotation_pairs(headline),\n",
    "        variety_of_vocabularity(headline),\n",
    "        count_sensational_words(headline),\n",
    "        count_absolute_words(headline),\n",
    "        objective_score(headline),\n",
    "        sentiment(headline)\n",
    "    ])\n",
    "\n",
    "data = pd.read_csv('labeled_RSS_posts.csv') #get labeled data\n",
    "\n",
    "#Split up sources randomly, aka by feed_title\n",
    "sources = data[\"feed_title\"].unique()\n",
    "train_sources, test_sources = train_test_split(sources, test_size=0.2, random_state=42)\n",
    "\n",
    "#Create train and test splits based on sources\n",
    "train_data = data[data[\"feed_title\"].isin(train_sources)]\n",
    "test_data = data[data[\"feed_title\"].isin(test_sources)]   ## ADJUST TEST SIZE BASED ON ENTRIES IN EACH OF THESE??\n",
    "#---------------------------------------\n",
    "\n",
    "# #Apply embeddings and feature calculations to each headline, combine features and glove embeddings\n",
    "# X_train = np.array([\n",
    "#     np.hstack((GLOVE_FUNCTION(row[\"entry_title\"], glove_model), extract_features(row[\"entry_title\"])))\n",
    "#     for index, row in train_data.iterrows()\n",
    "# ])\n",
    "\n",
    "# # Prepare testing data\n",
    "# X_test = np.array([\n",
    "#     np.hstack((GLOVE_FUNCTION(row[\"entry_title\"], glove_model), extract_features(row[\"entry_title\"])))\n",
    "#     for index, row in test_data.iterrows()\n",
    "# ])\n",
    "\n",
    "y_train = (train_data[\"credibility_label\"] == \"credible\").astype(int).values #1=credible, 0= uncredible\n",
    "y_test = (test_data[\"credibility_label\"] == \"credible\").astype(int).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1130d-4e1e-4741-8d6a-21bfc2aff250",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5dce69-3072-465b-872a-b74e062fc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
